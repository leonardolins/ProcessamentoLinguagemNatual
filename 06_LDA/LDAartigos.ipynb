{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZUCnaMmMewq"
   },
   "source": [
    "#Projeto de data sciencies em texto não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b370038e-edd0-42b6-985a-c30f6eea960b",
    "_uuid": "a9f0d9e1da1d1c9ce96322ecedc81d7a7847f043",
    "id": "3dbAf_6UePPt"
   },
   "source": [
    "\n",
    "# NIPS: Visualização de modelagem de tópicos\n",
    "\n",
    "Alguns tópicos principais do NIPS de acordo com [wikipedia] (https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems):\n",
    "\n",
    "1. Aprendizado de máquina,\n",
    "2. Estatísticas,\n",
    "3. Inteligência artificial,\n",
    "4. Neurociência computacional\n",
    "\n",
    "No entanto, os tópicos estão dentro do mesmo domínio, o que torna mais difícil distingui-los. Aqui neste Kernel tentarei extrair alguns tópicos usando a alocação de Dirichlet latente __LDA__. Este tutorial apresenta um pipeline de processamento de linguagem natural de ponta a ponta, começando com dados brutos e passando pela preparação, modelagem e visualização do papel. Iremos abordar os seguintes pontos\n",
    "\n",
    "\n",
    "1. Modelagem de tópico com ** LDA **\n",
    "1. Visualização de modelos de tópicos com ** pyLDAvis **\n",
    "1. Visualização dos resultados do LDA com ** t-SNE ** e ** bokeh **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 28409,
     "status": "ok",
     "timestamp": 1633378822822,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "HG2x0lWHJ7ms",
    "outputId": "529397e0-55e9-4296-b3d9-5f0f47d9f44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 6.9 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
      "Collecting numpy>=1.20.0\n",
      "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 196 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
      "Collecting pandas>=1.2.0\n",
      "  Downloading pandas-1.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 61.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136897 sha256=92e1719e3d051bf4790bfe35e65be7e1417f8a7f8e6217ae37ea554ea3195208\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: numpy, pandas, funcy, pyLDAvis\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.3 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed funcy-1.16 numpy-1.21.2 pandas-1.3.3 pyLDAvis-3.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy",
         "pandas"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:32:29.283569Z",
     "start_time": "2022-02-23T21:32:27.276826Z"
    },
    "_cell_guid": "a614ee7b-dc9a-4a69-a22a-6712176d67c2",
    "_uuid": "49cf47103ed18adfb84e28e636784cf89dbb3144",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1633378990769,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "gP7-aZ4hePPu",
    "outputId": "8b7679c8-9bfb-4173-83c1-0728e0e07306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.3.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from scipy import sparse as sp\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1633378991153,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "3XFrIzJO9dFN",
    "outputId": "f147fa2c-60bf-4746-f9a5-23bc897fa8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "workdir_path = '/content/drive/My Drive/'  # Inserir o local da pasta onde estão os arquivos de entrada (treino e teste)\n",
    "os.chdir(workdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:04.039987Z",
     "start_time": "2022-02-23T21:33:03.724815Z"
    },
    "_cell_guid": "9b886989-75f5-4522-b9d6-2a40737885f0",
    "_uuid": "eda4ba077f4beb7a55182bc37b147050f444827f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1633378991983,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "PpSqPeCsePPx",
    "outputId": "1a3afc86-45ae-46e6-ea4c-d18ea484d172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning with Symmetric Label Noise: The\\nImportance of Being Unhinged\\n\\nBrendan van Rooyen∗,†\\n∗\\n\\nAditya Krishna Menon†,∗\\n\\nThe Australian National University\\n\\n†\\n\\nRobert C. Williamson∗,†\\n\\nNational ICT Australia\\n\\n{ brendan.vanrooyen, aditya.menon, bob.williamson }@nicta.com.au\\n\\nAbstract\\nConvex potential minimisation is the de facto approach to binary classification.\\nHowever, Long and Servedio [2010] proved that under symmetric label noise\\n(SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly\\nshows that convex losses are not SLN-robust. In this paper, we propose a convex,\\nclassification-calibrated loss and prove that it is SLN-robust. The loss avoids the\\nLong and Servedio [2010] result by virtue of being negatively unbounded. The\\nloss is a modification of the hinge loss, where one does not clamp at zero; hence,\\nwe call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any\\nconvex potential; this implies that strong `2 regularisation makes most standard\\nlearners SLN-robust. Experiments confirm the unhinged loss’ SLN-robustness is\\nborne out in practice. So, with apologies to Wilde [1895], while the truth is rarely\\npure, it can be simple.\\n\\n1\\n\\nLearning with symmetric label noise\\n\\nBinary classification is the canonical supervised learning problem. Given an instance space X, and\\nsamples from some distribution D over X × {±1}, the goal is to learn a scorer s : X → R with low\\nmisclassification error on future samples drawn from D. Our interest is in the more realistic scenario\\nwhere the learner observes samples from some corruption D of D, where labels have some constant\\nprobability of being flipped, and the goal is still to perform well with respect to D. This problem is\\nknown as learning from symmetric label noise (SLN learning) [Angluin and Laird, 1988].\\nLong and Servedio [2010] showed that there exist linearly separable D where, when the learner\\nobserves some corruption D with symmetric label noise of any nonzero rate, minimisation of any\\nconvex potential over a linear function class results in classification performance on D that is equivalent to random guessing. Ostensibly, this establishes that convex losses are not “SLN-robust” and\\nmotivates the use of non-convex losses [Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010,\\nDing and Vishwanathan, 2010, Denchev et al., 2012, Manwani and Sastry, 2013].\\nIn this paper, we propose a convex loss and prove that it is SLN-robust. The loss avoids the result\\nof Long and Servedio [2010] by virtue of being negatively unbounded. The loss is a modification of the hinge loss where one does not clamp at zero; thus, we call it the unhinged loss. This\\nloss has several appealing properties, such as being the unique convex loss satisfying a notion of\\n“strong” SLN-robustness (Proposition 5), being classification-calibrated (Proposition 6), consistent\\nwhen minimised on D (Proposition 7), and having an simple optimal solution that is the difference\\nof two kernel means (Equation 8). Finally, we show that this optimal solution is equivalent to that of\\na strongly regularised SVM (Proposition 8), and any twice-differentiable convex potential (Proposition 9), implying that strong `2 regularisation endows most standard learners with SLN-robustness.\\n1\\n\\n\\x0cThe classifier resulting from minimising the unhinged loss is not new [Devroye et al., 1996, Chapter 10], [Schölkopf and Smola, 2002, Section 1.2], [Shawe-Taylor and Cristianini, 2004, Section\\n5.1]. However, establishing this classifier’s (strong) SLN-robustness, uniqueness thereof, and its\\nequivalence to a highly regularised SVM solution, to our knowledge is novel.\\n\\n2\\n\\nBackground and problem setup\\n\\nFix an instance space X. We denote by D a distribution over X × {±1}, with random variables\\n(X, Y) ∼ D. Any D may be expressed via the class-conditionals (P, Q) = (P(X | Y = 1), P(X |\\nY = −1)) and base rate π = P(Y = 1), or via the marginal M = P(X) and class-probability\\nfunction η : x 7→ P(Y = 1 | X = x). We interchangeably write D as DP,Q,π or DM,η .\\n2.1\\n\\nClassifiers, scorers, and risks\\n\\nA scorer is any function s : X → R. A loss is any function ` : {±1} × R → R. We use `−1 , `1 to\\nrefer to `(−1, ·) and `(1, ·). The `-conditional risk L` : [0, 1] × R → R is defined as L` : (η, v) 7→\\nη · `1 (v) + (1 − η) · `−1 (v). Given a distribution D, the `-risk of a scorer s is defined as\\n.\\n\\nLD\\n` (s) =\\n\\n[`(Y, s(X))] ,\\n\\nE\\n\\n(X,Y)∼D\\n\\n(1)\\n\\nD\\nso that LD\\n` (s) = E [L` (η(X), s(X))]. For a set S, L` (S) is the set of `-risks for all scorers in S.\\nX∼M\\n\\nA function class is any F ⊆ RX . Given some F, the set of restricted Bayes-optimal scorers for a\\nloss ` are those scorers in F that minimise the `-risk:\\n.\\n\\nSD,F,∗\\n= Argmin LD\\n` (s).\\n`\\ns∈F\\n\\nThe set of (unrestricted) Bayes-optimal scorers is SD,∗\\n= SD,F,∗\\nfor F = RX . The restricted\\n`\\n`\\n`-regret of a scorer is its excess risk over that of any restricted Bayes-optimal scorer:\\n.\\n\\nD\\nregretD,F\\n(s) = LD\\n` (s) − inf L` (t).\\n`\\nt∈F\\n\\nBinary classification is concerned with the zero-one loss, `01 : (y, v) 7→ Jyv < 0K + 21 Jv = 0K.\\nA loss ` is classification-calibrated if all its Bayes-optimal scorers are also optimal for zero-one\\nloss: (∀D) SD,∗\\n⊆ SD,∗\\n01 . A convex potential is any loss ` : (y, v) 7→ φ(yv), where φ : R → R+ is\\n`\\nconvex, non-increasing, differentiable with φ0 (0) < 0, and φ(+∞) = 0 [Long and Servedio, 2010,\\nDefinition 1]. All convex potentials are classification-calibrated [Bartlett et al., 2006, Theorem 2.1].\\n2.2\\n\\nLearning with symmetric label noise (SLN learning)\\n\\nThe problem of learning with symmetric label noise (SLN learning) is the following [Angluin and\\nLaird, 1988, Kearns, 1998, Blum and Mitchell, 1998, Natarajan et al., 2013]. For some notional\\n“clean” distribution D, which we would like to observe, we instead observe samples from some\\ncorrupted distribution SLN(D, ρ), for some ρ ∈ [0, 1/2). The distribution SLN(D, ρ) is such that\\nthe marginal distribution of instances is unchanged, but each label is independently flipped with\\nprobability ρ. The goal is to learn a scorer from these corrupted samples such that LD\\n01 (s) is small.\\nFor any quantity in D, we denote its corrupted counterparts in SLN(D, ρ) with a bar, e.g. M for\\nthe corrupted marginal distribution, and η for the corrupted class-probability function; additionally,\\nwhen ρ is clear from context, we will occasionally refer to SLN(D, ρ) by D. It is easy to check that\\nthe corrupted marginal distribution M = M , and [Natarajan et al., 2013, Lemma 7]\\n(∀x ∈ X) η(x) = (1 − 2ρ) · η(x) + ρ.\\n\\n3\\n\\n(2)\\n\\nSLN-robustness: formalisation\\n\\nWe consider learners (`, F) for a loss ` and a function class F, with learning being the search for\\nsome s ∈ F that minimises the `-risk. Informally, (`, F) is “robust” to symmetric label noise (SLNrobust) if minimising ` over F gives the same classifier on both the clean distribution D, which\\n2\\n\\n\\x0cthe learner would like to observe, and SLN(D, ρ) for any ρ ∈ [0, 1/2), which the learner actually\\nobserves. We now formalise this notion, and review what is known about SLN-robust learners.\\n3.1\\n\\nSLN-robust learners: a formal definition\\n\\nFor some fixed instance space X, let ∆ denote the set of distributions on X × {±1}. Given a notional\\n“clean” distribution D, Nsln : ∆ → 2∆ returns the set of possible corrupted versions of D the learner\\nmay observe, where labels are flipped with unknown probability ρ:\\n\\x1a\\n\\x14\\n\\x13\\x1b\\n1\\nNsln : D 7→ SLN(D, ρ) | ρ ∈ 0,\\n.\\n2\\nEquipped with this, we define our notion of SLN-robustness.\\nDefinition 1 (SLN-robustness). We say that a learner (`, F) is SLN-robust if\\nD,F,∗\\nD,F,∗\\n(∀D ∈ ∆) (∀D ∈ Nsln (D)) LD\\n) = LD\\n).\\n01 (S`\\n01 (S`\\n\\n(3)\\n\\nThat is, SLN-robustness requires that for any level of label noise in the observed distribution D, the\\nclassification performance (wrt D) of the learner is the same as if the learner directly observes D.\\nUnfortunately, a widely adopted class of learners is not SLN-robust, as we will now see.\\n3.2\\n\\nConvex potentials with linear function classes are not SLN-robust\\n\\nFix X = Rd , and consider learners with a convex potential `, and a function class of linear scorers\\nFlin = {x 7→ hw, xi | w ∈ Rd }.\\nThis captures e.g. the linear SVM and logistic regression, which are widely studied in theory and\\napplied in practice. Disappointingly, these learners are not SLN-robust: Long and Servedio [2010,\\nTheorem 2] give an example where, when learning under symmetric label noise, for any convex\\npotential `, the corrupted `-risk minimiser over Flin has classification performance equivalent to\\nrandom guessing on D. This implies that (`, Flin ) is not SLN-robust1 as per Definition 1.\\nProposition 1 (Long and Servedio [2010, Theorem 2]). Let X = Rd for any d ≥ 2. Pick any convex\\npotential `. Then, (`, Flin ) is not SLN-robust.\\n3.3\\n\\nThe fallout: what learners are SLN-robust?\\n\\nIn light of Proposition 1, there are two ways to proceed in order to obtain SLN-robust learners: either\\nwe change the class of losses `, or we change the function class F.\\nThe first approach has been pursued in a large body of work that embraces non-convex losses\\n[Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010, Ding and Vishwanathan, 2010,\\nDenchev et al., 2012, Manwani and Sastry, 2013]. While such losses avoid the conditions of Proposition 1, this does not automatically imply that they are SLN-robust when used with Flin . In Appendix\\nB, we present evidence that some of these losses are in fact not SLN-robust when used with Flin .\\nThe second approach is to consider suitably rich F that contains the Bayes-optimal scorer for D,\\ne.g. by employing a universal kernel. With this choice, one can still use a convex potential loss, and\\nin fact, owing to Equation 2, any classification-calibrated loss.\\nProposition 2. Pick any classification-calibrated `. Then, (`, RX ) is SLN-robust.\\nBoth approaches have drawbacks. The first approach has a computational penalty, as it requires\\noptimising a non-convex loss. The second approach has a statistical penalty, as estimation rates\\nwith a rich F will require a larger sample size. Thus, it appears that SLN-robustness involves a\\ncomputational-statistical tradeoff. However, there is a variant of the first option: pick a loss that is\\nconvex, but not a convex potential. Such a loss would afford the computational and statistical advantages of minimising convex risks with linear scorers. Manwani and Sastry [2013] demonstrated\\nthat square loss, `(y, v) = (1 − yv)2 , is one such loss. We will show that there is a simpler loss that\\nis convex and SLN-robust, but is not in the class of convex potentials by virtue of being negatively\\nunbounded. To derive this loss, we first re-interpret robustness via a noise-correction procedure.\\n1\\nEven if we were content with a difference of \\x0f ∈ [0, 1/2] between the clean and corrupted minimisers’\\nperformance, Long and Servedio [2010, Theorem 2] implies that in the worst case \\x0f = 1/2.\\n\\n3\\n\\n\\x0c4\\n\\nA noise-corrected loss perspective on SLN-robustness\\n\\nWe now re-express SLN-robustness to reason about optimal scorers on the same distribution, but\\nwith two different losses. This will help characterise a set of “strongly SLN-robust” losses.\\n4.1\\n\\nReformulating SLN-robustness via noise-corrected losses\\n\\nGiven any ρ ∈ [0, 1/2), Natarajan et al. [2013, Lemma 1] showed how to associate with a loss ` a\\nD\\nnoise-corrected counterpart ` such that LD\\n` (s) = L` (s). The loss ` is defined as follows.\\nDefinition 2 (Noise-corrected loss). Given any loss ` and ρ ∈ [0, 1/2), the noise-corrected loss ` is\\n(∀y ∈ {±1}) (∀v ∈ R) `(y, v) =\\n\\n(1 − ρ) · `(y, v) − ρ · `(−y, v)\\n.\\n1 − 2ρ\\n\\n(4)\\n\\nSince ` depends on the unknown parameter ρ, it is not directly usable to design an SLN-robust\\nlearner. Nonetheless, it is a useful theoretical device, since, by construction, for any F, SD,F,∗\\n=\\n`\\nSD,F,∗\\n= SD,F,∗\\n. This means that a sufficient condition for (`, F) to be SLN-robust is for SD,F,∗\\n.\\n`\\n`\\n`\\nGhosh et al. [2015, Theorem 1] proved a sufficient condition on ` such that this holds, namely,\\n(∃C ∈ R)(∀v ∈ R) `1 (v) + `−1 (v) = C.\\n(5)\\nInterestingly, Equation 5 is necessary for a stronger notion of robustness, which we now explore.\\n4.2\\n\\nCharacterising a stronger notion of SLN-robustness\\n\\nAs the first step towards a stronger notion of robustness, we rewrite (with a slight abuse of notation)\\nLD\\n` (s) =\\n\\nE\\n\\n(X,Y)∼D\\n\\n[`(Y, s(X))] =\\n\\nE\\n\\n(Y,S)∼R(D,s)\\n\\n.\\n\\n[`(Y, S)] = L` (R(D, s)),\\n\\nwhere R(D, s) is a distribution over labels and scores. Standard SLN-robustness requires that label\\nnoise does not change the `-risk minimisers, i.e. that if s is such that L` (R(D, s)) ≤ L` (R(D, s0 ))\\nfor all s0 , the same relation holds with D in place of D. Strong SLN-robustness strengthens this\\nnotion by requiring that label noise does not affect the ordering of all pairs of joint distributions over\\nlabels and scores. (This of course trivially implies SLN-robustness.) As with the definition of D,\\ngiven a distribution R over labels and scores, let R be the corresponding distribution where labels\\nare flipped with probability ρ. Strong SLN-robustness can then be made precise as follows.\\nDefinition 3 (Strong SLN-robustness). Call a loss ` strongly SLN-robust if for every ρ ∈ [0, 1/2),\\n(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L` (R) ≤ L` (R0 ).\\nWe now re-express strong SLN-robustness using a notion of order equivalence of loss pairs, which\\nsimply requires that two losses order all distributions over labels and scores identically.\\n˜ order equivalent if\\nDefinition 4 (Order equivalent loss pairs). Call a pair of losses (`, `)\\n(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L`˜(R) ≤ L`˜(R0 ).\\nClearly, order equivalence of (`, `) implies SD,F,∗\\n= SD,F,∗\\n, which in turn implies SLN-robustness.\\n`\\n`\\nIt is thus not surprising that we can relate order equivalence to strong SLN-robustness of `.\\nProposition 3. A loss ` is strongly SLN-robust iff for every ρ ∈ [0, 1/2), (`, `) are order equivalent.\\nThis connection now lets us exploit a classical result in decision theory about order equivalent losses\\nbeing affine transformations of each other. Combined with the definition of `, this lets us conclude\\nthat the sufficient condition of Equation 5 is also necessary for strong SLN-robustness of `.\\nProposition 4. A loss ` is strongly SLN-robust if and only if it satisfies Equation 5.\\nWe now return to our original goal, which was to find a convex ` that is SLN-robust for Flin (and\\nideally more general function classes). The above suggests that to do so, it is reasonable to consider\\nthose losses that satisfy Equation 5. Unfortunately, it is evident that if ` is convex, non-constant, and\\nbounded below by zero, then it cannot possibly be admissible in this sense. But we now show that\\nremoving the boundedness restriction allows for the existence of a convex admissible loss.\\n4\\n\\n\\x0c5\\n\\nThe unhinged loss: a convex, strongly SLN-robust loss\\n\\nConsider the following simple, but non-standard convex loss:\\nunh\\n`unh\\n1 (v) = 1 − v and `−1 (v) = 1 + v.\\n\\nCompared to the hinge loss, the loss does not clamp at zero, i.e. it does not have a hinge. (Thus, peculiarly, it is negatively unbounded, an issue we discuss in §5.3.) Thus, we call this the unhinged loss2 .\\nThe loss has a number of attractive properties, the most immediate being is its SLN-robustness.\\n5.1\\n\\nThe unhinged loss is strongly SLN-robust\\n\\nunh\\nunh\\nSince `unh\\nis strongly SLN-robust, and thus that\\n1 (v) + `−1 (v) = 2, Proposition 4 implies that `\\nunh\\n(` , F) is SLN-robust for any F. Further, the following uniqueness property is not hard to show.\\nProposition 5. Pick any convex loss `. Then,\\n\\n(∃C ∈ R) `1 (v) + `−1 (v) = C ⇐⇒ (∃A, B, D ∈ R) `1 (v) = −A · v + B, `−1 (v) = A · v + D.\\nThat is, up to scaling and translation, `unh is the only convex loss that is strongly SLN-robust.\\nReturning to the case of linear scorers, the above implies that (`unh , Flin ) is SLN-robust. This does\\nnot contradict Proposition 1, since `unh is not a convex potential as it is negatively unbounded. Intuitively, this property allows the loss to offset the penalty incurred by instances that are misclassified\\nwith high margin by awarding a “gain” for instances that correctly classified with high margin.\\n5.2\\n\\nThe unhinged loss is classification calibrated\\n\\nSLN-robustness is by itself insufficient for a learner to be useful. For example, a loss that is uniformly zero is strongly SLN-robust, but is useless as it is not classification-calibrated. Fortunately,\\nthe unhinged loss is classification-calibrated, as we now establish. For technical reasons (see §5.3),\\nwe operate with FB = [−B, +B]X , the set of scorers with range bounded by B ∈ [0, ∞).\\nProposition 6. Fix ` = `unh . For any DM,η , B ∈ [0, ∞), S`D,FB ,∗ = {x 7→ B · sign(2η(x) − 1)}.\\nThus, for every B ∈ [0, ∞), the restricted Bayes-optimal scorer over FB has the same sign as the\\nBayes-optimal classifier for 0-1 loss. In the limiting case where F = RX , the optimal scorer is\\nattainable if we operate over the extended reals R ∪ {±∞}, so that `unh is classification-calibrated.\\n5.3\\n\\nEnforcing boundedness of the loss\\n\\nWhile the classification-calibration of `unh is encouraging, Proposition 6 implies that its (unrestricted) Bayes-risk is −∞. Thus, the regret of every non-optimal scorer s is identically +∞, which\\nhampers analysis of consistency. In orthodox decision theory, analogous theoretical issues arise\\nwhen attempting to establish basic theorems with unbounded losses [Ferguson, 1967, pg. 78].\\nWe can side-step this issue by restricting attention to bounded scorers, so that `unh is effectively\\nbounded. By Proposition 6, this does not affect the classification-calibration of the loss. In the context of linear scorers, boundedness of scorers can be achieved by regularisation:\\ninstead of work√\\ning with Flin , one can instead use Flin,λ = {x 7→ hw, xi | ||w||2 ≤ 1/ λ}, where λ > 0, so\\nthat Flin,λ ⊆ FR/√λ for R = supx∈X ||x||2 . Observe that as (`unh , F) is SLN-robust for any F,\\n(`unh , Flin,λ ) is SLN-robust for any λ > 0. As we shall see in §6.3, working with Flin,λ also lets us\\nestablish SLN-robustness of the hinge loss when λ is large.\\n5.4\\n\\nUnhinged loss minimisation on corrupted distribution is consistent\\n\\nUsing bounded scorers makes it possible to establish a surrogate regret bound for the unhinged loss.\\nThis shows classification consistency of unhinged loss minimisation on the corrupted distribution.\\n2\\nThis loss has been considered in Sriperumbudur et al. [2009], Reid and Williamson [2011] in the context\\nof maximum mean discrepancy; see the Appendix. The analysis of its SLN-robustness is to our knowledge\\nnovel.\\n\\n5\\n\\n\\x0cProposition 7. Fix ` = `unh . Then, for any D, ρ ∈ [0, 1/2), B ∈ [1, ∞), and scorer s ∈ FB ,\\n1\\nD,FB\\nregretD\\n(s) =\\n· regret`D,FB (s).\\n01 (s) ≤ regret`\\n1 − 2ρ\\nStandard rates of convergence via generalisation bounds are also trivial to derive; see the Appendix.\\n\\n6\\n\\nLearning with the unhinged loss and kernels\\n\\nWe now show that the optimal solution for the unhinged loss when employing regularisation and\\nkernelised scorers has a simple form. This sheds further light on SLN-robustness and regularisation.\\n6.1\\n\\nThe centroid classifier optimises the unhinged loss\\n\\nConsider minimising the unhinged\\nrisk over the class of kernelised scorers FH,λ = {s : x 7→\\n√\\nhw, Φ(x)iH | ||w||H ≤ 1/ λ} for some λ > 0, where Φ : X → H is a feature mapping into a\\nreproducing kernel Hilbert space H with kernel k. Equivalently, given a distribution3 D, we want\\nλ\\n∗\\nwunh,λ\\n= argmin E [1 − Y · hw, Φ(X)i] + hw, wiH .\\n(6)\\n2\\n(X,Y)∼D\\nw∈H\\nThe first-order optimality condition implies that\\n1\\n∗\\n(7)\\nwunh,λ\\n= · E [Y · Φ(X)] ,\\nλ (X,Y)∼D\\nwhich is the kernel mean map of D [Smola et al., 2007], and thus the optimal unhinged scorer is\\n\\x12\\n\\x13\\n1\\n1\\ns∗unh,λ : x 7→ · E [Y · k(X, x)] = x 7→ · π · E [k(X, x)] − (1 − π) · E [k(X, x)] .\\nX∼P\\nX∼Q\\nλ (X,Y)∼D\\nλ\\n(8)\\nFrom Equation 8, the unhinged solution is equivalent to a nearest centroid classifier [Manning et al.,\\n2008, pg. 181] [Tibshirani et al., 2002] [Shawe-Taylor and Cristianini, 2004, Section 5.1]. Equation\\n8 gives a simple way to understand the SLN-robustness of (`unh , FH,λ ), as the optimal scorers on\\nthe clean and corrupted distributions only differ by a scaling (see the Appendix):\\n\\x03\\n\\x02\\n1\\n· E\\nY · k(X, x) .\\n(9)\\n(∀x ∈ X) E [Y · k(X, x)] =\\n1 − 2ρ (X,Y)∼D\\n(X,Y)∼D\\nInterestingly, Servedio [1999, Theorem 4] established that a nearest centroid classifier (which they\\ntermed “AVERAGE ”) is robust to a general class of label noise, but required the assumption that\\nM is uniform over the unit sphere. Our result establishes that SLN robustness of the classifier\\nholds without any assumptions on M . In fact, Ghosh et al. [2015, Theorem 1] lets one quantify the\\nunhinged loss’ performance under a more general noise model; see the Appendix for discussion.\\n6.2\\n\\nPractical considerations\\n\\nWe note several points relating to practical usage of the unhinged loss with kernelised scorers. First,\\ncross-validation is not required to select λ, since changing λ only changes the magnitude of scores,\\nnot their sign. Thus, for the purposes of classification, one can simply use λ = 1.\\nSecond, we can easily extend the scorers to use a bias regularised with strength 0 < λb 6= λ. Tuning\\nλb is equivalent to computing s∗unh,λ as per Equation 8, and tuning a threshold on a holdout set.\\n∗\\nThird, when H = Rd for d small, we can store wunh,λ\\nexplicitly, and use this to make predictions.\\nFor high (or infinite) dimensional H, we can either make predictions directly via Equation 8, or\\nuse random Fourier features [Rahimi and Recht, 2007] to (approximately) embed H into some low∗\\ndimensional Rd , and then store wunh,λ\\nas usual. (The latter requires a translation-invariant kernel.)\\n∗\\nWe now show that under some assumptions, wunh,λ\\ncoincides with the solution of two established\\nmethods; the Appendix discusses some further relationships, e.g. to the maximum mean discrepancy.\\n3\\n\\nGiven a training sample S ∼ Dn , we can use plugin estimates as appropriate.\\n\\n6\\n\\n\\x0c6.3\\n\\nEquivalence to a highly regularised SVM and other convex potentials\\n\\nThere is an interesting equivalence between the unhinged solution and that of a highly regularised\\nSVM. This has been noted in e.g. Hastie et al. [2004, Section 6], which showed how SVMs approach\\na nearest centroid classifier, which is of course the optimal unhinged solution.\\nProposition 8. Pick any D and Φ : X → H with R = supx∈X ||Φ(x)||H < ∞. For any λ > 0, let\\n∗\\nwhinge,λ\\n= argmin\\nw∈H\\n\\nE\\n\\n(X,Y)∼D\\n\\n[max(0, 1 − Y · hw, Φ(x)iH )] +\\n\\nλ\\nhw, wiH\\n2\\n\\n∗\\n∗\\nbe the soft-margin SVM solution. Then, if λ ≥ R2 , whinge,λ\\n= wunh,λ\\n.\\n\\nSince (`unh , FH,λ ) is SLN-robust, it follows that for `hinge : (y, v) 7→ max(0, 1−yv), (`hinge , FH,λ )\\nis similarly SLN-robust provided λ is sufficiently large. That is, strong `2 regularisation (and a\\nbounded feature map) endows the hinge loss with SLN-robustness4 . Proposition 8 can be generalised\\n∗\\nto show that wunh,λ\\nis the limiting solution of any twice differentiable convex potential. This shows\\nthat strong `2 regularisation endows most learners with SLN-robustness. Intuitively, with strong\\nregularisation, one only considers the behaviour of a loss near zero; since a convex potential φ has\\nφ0 (0) < 0, it will behave similarly to its linear approximation around zero, viz. the unhinged loss.\\nProposition 9. Pick any D, bounded feature mapping Φ : X → H, and twice differentiable convex\\n∗\\npotential φ with φ00 ([−1, 1]) bounded. Let wφ,λ\\nbe the minimiser of the regularised φ risk. Then,\\n\\x0c\\x0c\\n\\x0c\\x0c2\\n∗\\n\\x0c\\x0c w ∗\\n\\x0c\\x0c\\nwunh,λ\\n\\x0c\\x0c\\n\\x0c\\x0c\\nφ,λ\\nlim \\x0c\\x0c ∗\\n−\\n\\x0c\\x0c = 0.\\n∗\\nλ→∞ \\x0c\\x0c ||wφ,λ ||H\\n||wunh,λ\\n||H \\x0c\\x0c\\nH\\n\\n6.4\\n\\nEquivalence to Fisher Linear Discriminant with whitened data\\n\\nFor binary classification on DM,η , the Fisher Linear Discriminant (FLD) finds a weight vector proportional to the minimiser of square loss `sq : (y, v) 7→ (1 − yv)2 [Bishop, 2006, Section 4.1.5],\\n∗\\nwsq,λ\\n= (EX∼M [XXT ] + λI)−1 · E(X,Y)∼D [Y · X].\\n\\n(10)\\n\\n∗\\nwsq,λ\\n\\nis only changed by a scaling\\nBy Equation 9, and the fact that the corrupted marginal M = M ,\\nfactor under label noise. This provides an alternate proof of the fact that (`sq , Flin ) is SLN-robust5\\n∗\\n[Manwani and Sastry, 2013, Theorem 2]. Clearly, the unhinged loss solution wunh,λ\\nis equivalent to\\n\\x02 T\\x03\\n∗\\nthe FLD and square loss solution wsq,λ when the input data is whitened i.e. E XX = I. With\\nX∼M\\n\\na well-specified F, e.g. with a universal kernel, both the unhinged and square loss asymptotically\\nrecover the optimal classifier, but the unhinged loss does not require a matrix inversion. With a\\nmisspecified F, one cannot in general argue for the superiority of the unhinged loss over square loss,\\nor vice-versa, as there is no universally good surrogate to the 0-1 loss [Reid and Williamson, 2010,\\nAppendix A]; the Appendix illustrate examples where both losses may underperform.\\n\\n7\\n\\nSLN-robustness of unhinged loss: empirical illustration\\n\\nWe now illustrate that the unhinged loss’ SLN-robustness is empirically manifest. We reiterate\\nthat with high regularisation, the unhinged solution is equivalent to an SVM (and in the limit any\\nclassification-calibrated loss) solution. Thus, we do not aim to assert that the unhinged loss is\\n“better” than other losses, but rather, to demonstrate that its SLN-robustness is not purely theoretical.\\nWe first show that the unhinged risk minimiser performs well on the example of Long\\nand Servedio [2010] (henceforth LS10). Figure 1 shows the distribution D, where X =\\n{(1, 0), (γ, 5γ), (γ, −γ)} ⊂ R2 , with marginal distribution M = { 14 , 14 , 12 } and all three instances\\nare deterministically positive. We pick γ = 1/2. The unhinged minimiser perfectly classifies all\\nthree points, regardless of the level of label noise (Figure 1). The hinge minimiser is perfect when\\nthere is no noise, but with even a small amount of noise, achieves a 50% error rate.\\n4\\n5\\n\\nLong and Servedio [2010, Section 6] show that `1 regularisation does not endow SLN-robustness.\\nSquare loss escapes the result of Long and Servedio [2010] since it is not monotone decreasing.\\n\\n7\\n\\n\\x0c1\\n\\nUnhinged\\nHinge 0% noise\\nHinge 1% noise\\n\\n0.5\\n\\n0.5\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n1\\n\\n−0.5\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.15 ± 0.27\\n0.21 ± 0.30\\n0.38 ± 0.37\\n0.42 ± 0.36\\n0.47 ± 0.38\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.22 ± 0.08\\n0.22 ± 0.08\\n0.39 ± 0.23\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.34 ± 0.48\\n\\nTable 1: Mean and standard deviation of the 01 error over 125 trials on LS10. Grayed cells\\ndenote the best performer at that noise rate.\\n\\n−1\\n\\nFigure 1: LS10 dataset.\\n\\nWe next consider empirical risk minimisers from a random training sample: we construct a training\\nset of 800 instances, injected with varying levels of label noise, and evaluate classification performance on a test set of 1000 instances. We compare the hinge, t-logistic (for t = 2) [Ding and\\nVishwanathan, 2010] and unhinged minimisers using a linear scorer without a bias term, and regularisation strength λ = 10−16 . From Table 1, even at 40% label noise, the unhinged classifier is able\\nto find a perfect solution. By contrast, both other losses suffer at even moderate noise rates.\\nWe next report results on some UCI datasets, where we additionally tune a threshold so as to ensure\\nthe best training set 0-1 accuracy. Table 2 summarises results on a sample of four datasets. (The\\nAppendix contains results with more datasets, performance metrics, and losses.) Even at noise close\\nto 50%, the unhinged loss is often able to learn a classifier with some discriminative power.\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.01 ± 0.03\\n0.06 ± 0.12\\n0.17 ± 0.20\\n0.35 ± 0.24\\n0.60 ± 0.20\\n\\n0.00 ± 0.00\\n0.01 ± 0.03\\n0.04 ± 0.05\\n0.09 ± 0.11\\n0.24 ± 0.16\\n0.49 ± 0.20\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.01\\n0.02 ± 0.07\\n0.13 ± 0.22\\n0.45 ± 0.33\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.05 ± 0.00\\n0.06 ± 0.01\\n0.06 ± 0.01\\n0.08 ± 0.04\\n0.14 ± 0.10\\n0.45 ± 0.26\\n\\n0.05 ± 0.00\\n0.07 ± 0.02\\n0.08 ± 0.03\\n0.11 ± 0.05\\n0.24 ± 0.13\\n0.49 ± 0.16\\n\\n0.05 ± 0.00\\n0.05 ± 0.00\\n0.05 ± 0.00\\n0.05 ± 0.01\\n0.09 ± 0.10\\n0.46 ± 0.30\\n\\n(a) iris.\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\n(b) housing.\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.10 ± 0.08\\n0.19 ± 0.11\\n0.31 ± 0.13\\n0.39 ± 0.13\\n0.50 ± 0.16\\n\\n0.00 ± 0.00\\n0.11 ± 0.02\\n0.15 ± 0.02\\n0.22 ± 0.03\\n0.33 ± 0.04\\n0.48 ± 0.04\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.01 ± 0.00\\n0.02 ± 0.02\\n0.34 ± 0.21\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n(c) usps0v7.\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.05 ± 0.00\\n0.15 ± 0.03\\n0.21 ± 0.03\\n0.25 ± 0.03\\n0.31 ± 0.05\\n0.48 ± 0.09\\n\\n0.04 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.40 ± 0.24\\n\\n0.19 ± 0.00\\n0.19 ± 0.01\\n0.19 ± 0.01\\n0.19 ± 0.03\\n0.22 ± 0.05\\n0.45 ± 0.08\\n\\n(d) splice.\\n\\nTable 2: Mean and standard deviation of the 0-1 error over 125 trials on UCI datasets.\\n\\n8\\n\\nConclusion and future work\\n\\nWe proposed a convex, classification-calibrated loss, proved that is robust to symmetric label noise\\n(SLN-robust), showed it is the unique loss that satisfies a notion of strong SLN-robustness, established that it is optimised by the nearest centroid classifier, and showed that most convex potentials,\\nsuch as the SVM, are also SLN-robust when highly regularised. So, with apologies to Wilde [1895]:\\nWhile the truth is rarely pure, it can be simple.\\nAcknowledgments\\nNICTA is funded by the Australian Government through the Department of Communications and\\nthe Australian Research Council through the ICT Centre of Excellence Program. The authors thank\\nCheng Soon Ong for valuable comments on a draft of this paper.\\n8\\n\\n\\x0cReferences\\nDana Angluin and Philip Laird. Learning from noisy examples. Machine Learning, 2(4):343–370, 1988.\\nPeter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification, and risk bounds. Journal\\nof the American Statistical Association, 101(473):138 – 156, 2006.\\nChristopher M Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.\\nAvrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Conference on\\nComputational Learning Theory (COLT), pages 92–100, 1998.\\nVasil Denchev, Nan Ding, Hartmut Neven, and S.V.N. Vishwanathan. Robust classification with adiabatic\\nquantum optimization. In International Conference on Machine Learning (ICML), pages 863–870, 2012.\\nLuc Devroye, László Györfi, and Gábor Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, 1996.\\nNan Ding and S.V.N. Vishwanathan. t-logistic regression. In Advances in Neural Information Processing\\nSystems (NIPS), pages 514–522. Curran Associates, Inc., 2010.\\nThomas S. Ferguson. Mathematical Statistics: A Decision Theoretic Approach. Academic Press, 1967.\\nAritra Ghosh, Naresh Manwani, and P. S. Sastry. Making risk minimization tolerant to label noise. Neurocomputing, 160:93 – 107, 2015.\\nTrevor Hastie, Saharon Rosset, Robert Tibshirani, and Ji Zhu. The entire regularization path for the support\\nvector machine. Journal of Machine Learning Research, 5:1391–1415, December 2004. ISSN 1532-4435.\\nMichael Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 5(6):392–401,\\nNovember 1998.\\nPhilip M. Long and Rocco A. Servedio. Random classification noise defeats all convex potential boosters.\\nMachine Learning, 78(3):287–304, 2010. ISSN 0885-6125.\\nChristopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. Introduction to Information Retrieval.\\nCambridge University Press, New York, NY, USA, 2008. ISBN 0521865719, 9780521865715.\\nNaresh Manwani and P. S. Sastry. Noise tolerance under risk minimization. IEEE Transactions on Cybernetics,\\n43(3):1146–1151, June 2013.\\nHamed Masnadi-Shirazi, Vijay Mahadevan, and Nuno Vasconcelos. On the design of robust classifiers for\\ncomputer vision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.\\nNagarajan Natarajan, Inderjit S. Dhillon, Pradeep D. Ravikumar, and Ambuj Tewari. Learning with noisy\\nlabels. In Advances in Neural Information Processing Systems (NIPS), pages 1196–1204, 2013.\\nAli Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances in Neural\\nInformation Processing Systems (NIPS), pages 1177–1184, 2007.\\nMark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine Learning Research,\\n11:2387–2422, December 2010.\\nMark D Reid and Robert C Williamson. Information, divergence and risk for binary experiments. Journal of\\nMachine Learning Research, 12:731–817, Mar 2011.\\nBernhard Schölkopf and Alexander J Smola. Learning with kernels, volume 129. MIT Press, 2002.\\nRocco A. Servedio. On PAC learning using Winnow, Perceptron, and a Perceptron-like algorithm. In Conference on Computational Learning Theory (COLT), 1999.\\nJohn Shawe-Taylor and Nello Cristianini. Kernel Methods for Pattern Analysis. Cambridge Uni. Press, 2004.\\nAlex Smola, Arthur Gretton, Le Song, and Bernhard Schölkopf. A Hilbert space embedding for distributions.\\nIn Algorithmic Learning Theory (ALT), 2007.\\nBharath K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Gert R. G. Lanckriet, and Bernhard Schölkopf.\\nKernel choice and classifiability for RKHS embeddings of probability distributions. In Advances in Neural\\nInformation Processing Systems (NIPS), 2009.\\nGuillaume Stempfel and Liva Ralaivola. Learning SVMs from sloppily labeled data. In Artificial Neural\\nNetworks (ICANN), volume 5768, pages 884–893. Springer Berlin Heidelberg, 2009.\\nRobert Tibshirani, Trevor Hastie, Balasubramanian Narasimhan, and Gilbert Chu. Diagnosis of multiple cancer\\ntypes by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences, 99(10):\\n6567–6572, 2002.\\nOscar Wilde. The Importance of Being Earnest, 1895.\\n\\n9\\n\\n\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df = pd.read_csv('papers/Papers.csv')\n",
    "docs = array(p_df['PaperText'])\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7364c06e-8044-4da4-9b50-4daa5bf5765e",
    "_uuid": "365398b9b4072a8c5bf3c8de0067122e70fff748",
    "id": "OYeZKng1ePPz"
   },
   "source": [
    "## Primeiro pré-processar deixando todo em minuscula e tokenizar o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:13.632030Z",
     "start_time": "2022-02-23T21:33:11.436041Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1633378992322,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "pn-4I7gqV5xk",
    "outputId": "38a50f7b-6647-42b2-945a-f094a886cee1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/LeonardoLins/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:13.647150Z",
     "start_time": "2022-02-23T21:33:13.636408Z"
    },
    "_cell_guid": "125f9eb3-99d9-422a-8242-384da62d43dd",
    "_uuid": "f10f622826eaa4e9bd97c1414aac5538ddabafd2",
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1633378992322,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "_jFrxinGePPz"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def docs_preprocessor(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for idx in range(len(docs)):\n",
    "        docs[idx] = str(docs[idx]).lower()  # Convert to lowercase.\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "    # Remove numbers, but not words that contain numbers.\n",
    "    docs = [[token for token in doc if not token.isdigit()] for doc in docs]\n",
    "    \n",
    "    # Remove words that are only one character.\n",
    "    docs = [[token for token in doc if len(token) > 3] for doc in docs]\n",
    "    \n",
    "    # Lemmatize all words in documents.\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "  \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:27.516048Z",
     "start_time": "2022-02-23T21:33:13.650787Z"
    },
    "_cell_guid": "c87ebee3-e88b-4233-9000-b71103f281c3",
    "_uuid": "790063fc1a341eb17e0244c220de736d51196cfe",
    "executionInfo": {
     "elapsed": 8714,
     "status": "ok",
     "timestamp": 1633379001034,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "XuXIp0hWePP2"
   },
   "outputs": [],
   "source": [
    "docs = docs_preprocessor(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b167c49c-6187-4921-9d2b-2fa1ba8377a4",
    "_uuid": "f649c357b776963b7e626064fa6ced1a03a3219d",
    "id": "-GZlfsohePP4"
   },
   "source": [
    "### **Computar bigramas e trigramas :**\n",
    "Sine tópicos são muito semelhantes, o que os faria distingui-los são frases ao invés de palavras únicas / individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:57.603850Z",
     "start_time": "2022-02-23T21:33:27.519289Z"
    },
    "_cell_guid": "66b3e9bf-1c76-4ee1-bb22-60405308c401",
    "_uuid": "d6ce91b0d51d55e3504cbb352f0548cffcdb0169",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19249,
     "status": "ok",
     "timestamp": 1633379020281,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "PeYS98CfePP4",
    "outputId": "6f13d6c8-0e5b-4c9f-c4bd-a4b7d3492b7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "# Add bigrams and trigrams to docs (only ones that appear 10 times or more).\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "trigram = Phrases(bigram[docs])\n",
    "\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)\n",
    "    for token in trigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:57.659597Z",
     "start_time": "2022-02-23T21:33:57.605981Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633379020282,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "V2bUTDbpOfpL",
    "outputId": "defa1e92-961d-469c-9a65-435407d80982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases<556123 vocab, min_count=10, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:57.670066Z",
     "start_time": "2022-02-23T21:33:57.663901Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633379020282,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "nWzohYYpOydW",
    "outputId": "78ce56aa-e9b6-4fb5-f7ad-d76efcea82b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrases<616916 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b9849dae-b405-4bc6-ab61-c062f2a13746",
    "_uuid": "c75a2e62b9a0e570a0a34b84af5912c22aa9ba28",
    "id": "GXcCXaDSePP7"
   },
   "source": [
    "### Remover Tokens comuns e pouco comuns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:59.224358Z",
     "start_time": "2022-02-23T21:33:57.673560Z"
    },
    "_cell_guid": "df440d67-082a-4b2d-a6fb-80029af194b5",
    "_uuid": "73f7ba9fedcde10c4e70cf2456c7ef20c8e32d35",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1633379021578,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "qRe_v6O5ePP7",
    "outputId": "df87e115-34dc-4697-a2b7-573d526f74a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in initital documents: 39534\n",
      "Number of unique words after removing rare and common words: 6001\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "print('Number of unique words in initital documents:', len(dictionary))\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 20% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
    "print('Number of unique words after removing rare and common words:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac2ede6e-8815-4da1-a739-1ffc71614cb9",
    "_uuid": "f5e4e52fe4ff798ac96f8f23538770c5cc4d217a",
    "id": "1KLQtDWtePP-"
   },
   "source": [
    "Eliminando as palavras comuns e raras, acabamos com apenas cerca de 6% das palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e6a6363-b43f-45f0-80d9-0f5b5b9462fc",
    "_uuid": "78cd228789c6fa5d094886b58dce875f63625c33",
    "id": "5tkGL0wBePP-"
   },
   "source": [
    "** Vetorizar dados: **\n",
    "A primeira etapa é obter uma representação por trás das palavras de cada documento.\n",
    "Passos\n",
    "1-converter um corpus\n",
    "doc2bow:converter documento (uma lista de palavras) no formato de saco de palavras = lista de (token_id, token_count) 2-tuplas. Cada palavra é considerada uma string tokenizada e normalizada (codificada em unicode ou em utf8). Nenhum outro pré-processamento é feito nas palavras do documento; aplique tokenização, lematização etc. antes de chamar esse método.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99BKWfcYyOjf"
   },
   "source": [
    "## precisso de 3 coisas para o algoritmo funcionar: Corpus um dicionario e o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:59.983610Z",
     "start_time": "2022-02-23T21:33:59.228563Z"
    },
    "_cell_guid": "ca1d1e18-2939-4880-bca7-712d4bc42735",
    "_uuid": "27e71950ec4bca8f6b62ec6d6cd9f613a50019ea",
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1633379022369,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "JGXwd5TZePP_"
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:33:59.995028Z",
     "start_time": "2022-02-23T21:33:59.986460Z"
    },
    "_cell_guid": "ad5717c6-b2e8-4122-8c7d-b5bca9dfb1ab",
    "_uuid": "80752c24b3b1bab16b48054a6ca6e7fb84d49372",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1633379022369,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "2gY7iFHjePQB",
    "outputId": "09075e31-488c-48ad-e246-9d3eecb713ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 6001\n",
      "Number of documents: 403\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0a1a95d-8ed7-47a1-a1b0-0471a77e9af0",
    "_uuid": "bb7f095fc6b213d727b36798294d56a6ab950f5b",
    "id": "hBlY7rrUePQD"
   },
   "source": [
    "\n",
    "\n",
    "Com o corpus de bag of words, podemos prosseguir para aprender nosso modelo de tópico a partir dos documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff8fbb06-d7f2-4170-b91c-151e3c5c9cad",
    "_uuid": "49a8f93233d2640b476e093390182e21102ae555",
    "id": "No58jWGgePQD"
   },
   "source": [
    "# Entrenando LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:34:00.007052Z",
     "start_time": "2022-02-23T21:34:00.001401Z"
    },
    "_cell_guid": "f15e826a-f41b-410a-9ff9-ef19edc05085",
    "_uuid": "b11f495c4fcf6991c523d5a3b6669506f39533ee",
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633379022370,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Fb1p3x-MePQD"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:35:26.034203Z",
     "start_time": "2022-02-23T21:34:00.012666Z"
    },
    "_cell_guid": "5f8f0fa0-b911-4043-af2c-ec311384d7a5",
    "_uuid": "084c1198f0e528c52edc746436d797c855de8c51",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33682,
     "status": "ok",
     "timestamp": 1633379056049,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "0NNGy2ZmePQF",
    "outputId": "30ad864f-de6b-4185-a216-69019036ac50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 600 ms, total: 1min 24s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 4\n",
    "chunksize = 500 # size of the doc looked at every pass\n",
    "passes = 20 # number of passes through documents\n",
    "iterations = 400\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "%time model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, \\\n",
    "                       alpha='auto', eta='auto', \\\n",
    "                       iterations=iterations, num_topics=num_topics, \\\n",
    "                       passes=passes, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93191a68-99d9-4b7d-88b2-5b75e3f44b1d",
    "_uuid": "f5f7c3e213b2fdffa3c767ebd5a1eb7631e76b13",
    "id": "-nUU7q-OePQI"
   },
   "source": [
    "# Como escolher a quantidade de tópicos?\n",
    "__LDA__ é uma técnica não supervisionada, o que significa que não sabemos antes de executar o modelo quantos tópicos existem em nosso corpus. A coerência do tópico é uma das principais técnicas utilizadas para desestimar o número de tópicos. Você pode ler sobre isso [aqui.] (Http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)\n",
    "\n",
    "No entanto, usei a ferramenta de visualização LDA ** pyLDAvis **, tentei alguns tópicos e comparei os resultados. Quatro pareciam ser o número ideal de tópicos que separariam mais os tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:35:26.185069Z",
     "start_time": "2022-02-23T21:35:26.037785Z"
    },
    "_cell_guid": "8b9015bc-0e3d-4ee9-9d79-92f2d9dba89f",
    "_uuid": "7e100266faefe67e6ce1131fa464c78630293984",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1633379056050,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "4fk6tS_cePQI",
    "outputId": "8a3e0a81-6aaa-4cb5-ef86-b6cb560d5d80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T21:35:30.246689Z",
     "start_time": "2022-02-23T21:35:26.188790Z"
    },
    "_cell_guid": "483a506d-d21b-4219-948d-87ae641b04ab",
    "_uuid": "f195b367d556a559c4db98446e9c9148758a95f6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "executionInfo": {
     "elapsed": 2923,
     "status": "ok",
     "timestamp": 1633379058962,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "wCAN5DPxePQK",
    "outputId": "87b834b0-6464-4c04-a5d3-3e233a45d6b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el354845377146081123936335\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el354845377146081123936335_data = {\"mdsDat\": {\"x\": [0.08155492258820402, -0.02398590765387979, 0.12446908253265972, -0.1820380974669841], \"y\": [0.020833168053152395, -0.13698989007780557, 0.05272331442488458, 0.06343340759976855], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [28.901733236966535, 25.234737037979933, 23.496024929594352, 22.367504795459165]}, \"tinfo\": {\"Term\": [\"regret\", \"gaussian_process\", \"convergence_rate\", \"convolutional\", \"bandit\", \"matrix_completion\", \"variational_inference\", \"recurrent\", \"rank_matrix\", \"recurrent_neural\", \"fully_connected\", \"lstm\", \"step_size\", \"submodular\", \"deep_learning\", \"regret_bound\", \"strongly_convex\", \"singular_value\", \"convolutional_neural\", \"hidden_layer\", \"gibbs_sampling\", \"sample_complexity\", \"during_training\", \"round\", \"markov_chain\", \"topic_model\", \"line_search\", \"posterior_distribution\", \"pixel\", \"tensor\", \"exact_recovery\", \"linear_measurement\", \"incoherence\", \"restricted_strong\", \"matrix_completion\", \"dantzig_selector\", \"statistical_guarantee\", \"weighted_graph\", \"sparse_recovery\", \"sanghavi\", \"benjamin_recht\", \"mcsherry\", \"singular_vector\", \"compressed_sensing\", \"privacy\", \"dantzig\", \"sujay_sanghavi\", \"rank_matrix\", \"tensor_decomposition\", \"singular_value\", \"martinsson\", \"incoherent\", \"edge_weight\", \"netrapalli\", \"singular\", \"sujay\", \"semidefinite_programming\", \"recovery\", \"halko\", \"need_least\", \"clique\", \"completion\", \"calibration\", \"sketching\", \"private\", \"bipartite_graph\", \"rank_approximation\", \"nuclear_norm\", \"frobenius_norm\", \"decision_rule\", \"parent\", \"tensor\", \"vertex\", \"active_learning\", \"bayesian_network\", \"alternating_minimization\", \"decision_tree\", \"relative_error\", \"spectral_norm\", \"sample_complexity\", \"estimation_error\", \"causal\", \"data_set\", \"lasso\", \"multi_label\", \"graphical_model\", \"query\", \"subspace\", \"running_time\", \"probability_least\", \"least_square\", \"sample_size\", \"polynomial_time\", \"principal_component\", \"covariance_matrix\", \"topic_model\", \"bayesian_nonparametric\", \"variational_distribution\", \"variational_parameter\", \"metropolis_hastings\", \"black_variational\", \"posterior_predictive\", \"gibbs_sampler\", \"posterior_mean\", \"mcmc\", \"gibbs_sampling\", \"blei_jordan\", \"squared_exponential\", \"latent_dirichlet\", \"hamiltonian_monte\", \"variational_objective\", \"sampler\", \"poisson_process\", \"posterior_inference\", \"markov_chain_monte_carlo\", \"titsias\", \"conjugacy\", \"proposal_distribution\", \"point_process\", \"acceptance\", \"variational_posterior\", \"hamiltonian\", \"wake\", \"true_posterior\", \"covariance_function\", \"approximate_posterior\", \"optimal_control\", \"stochastic_variational\", \"particle\", \"mean_field\", \"predictive_distribution\", \"full_posterior\", \"gaussian_process\", \"posterior_distribution\", \"gibbs\", \"marginal_likelihood\", \"variational_inference\", \"dirichlet_process\", \"latent_state\", \"bayesian_inference\", \"dirichlet\", \"trajectory\", \"mixture_model\", \"market\", \"hidden_markov\", \"state_space\", \"exponential_family\", \"markov_chain\", \"policy\", \"decision_making\", \"belief\", \"reinforcement_learning\", \"covariance_matrix\", \"generative_model\", \"trial\", \"population\", \"poisson\", \"agent\", \"stationary_distribution\", \"closed_form\", \"time_series\", \"neuron\", \"document\", \"regret\", \"regret_bound\", \"bandit_problem\", \"bandit_feedback\", \"multi_armed\", \"bandit\", \"regret_minimization\", \"bubeck\", \"player\", \"expected_reward\", \"accelerated_proximal\", \"regret_regret\", \"multiarmed_bandit\", \"strong_convexity\", \"current_iterate\", \"multi_armed_bandit_problem\", \"bianchi_regret\", \"upper_confidence\", \"fischer_finite\", \"richta_taka\", \"peter_auer\", \"stochastic_nonstochastic\", \"bandit_setting\", \"welfare\", \"bubeck_cesa\", \"stochastic_bandit\", \"game_cambridge\", \"bianchi_lugosi\", \"nonstochastic\", \"multiarmed\", \"primal_dual\", \"strongly_convex\", \"submodular_maximization\", \"cumulative_regret\", \"armed\", \"bianchi\", \"cesa\", \"arm\", \"submodular\", \"dual_variable\", \"line_search\", \"linear_convergence\", \"submodular_function\", \"each_round\", \"round\", \"convergence_rate\", \"reward_function\", \"iteration_complexity\", \"greedy_algorithm\", \"coordinate_descent\", \"step_size\", \"game\", \"primal\", \"online_learning\", \"reward\", \"proximal\", \"empirical_risk\", \"greedy\", \"item\", \"gradient_descent\", \"ranking\", \"optimal_solution\", \"random_walk\", \"logistic_regression\", \"time_step\", \"stochastic_optimization\", \"convolutional_layer\", \"lstm\", \"object_recognition\", \"pooling_layer\", \"autoencoder\", \"object_detection\", \"encoder_decoder\", \"semantic_segmentation\", \"very_deep\", \"parsing\", \"recurrent_connection\", \"convolutional\", \"recurrent_convolutional\", \"convolutional_network\", \"input_image\", \"visual_recognition\", \"softmax_layer\", \"relu\", \"convnets\", \"machine_translation\", \"weakly_supervised\", \"image_caption\", \"lstms\", \"ilya_sutskever\", \"sutskever\", \"patch\", \"krizhevsky_sutskever\", \"rnns\", \"input_sequence\", \"krizhevsky\", \"convolutional_neural\", \"recurrent_network\", \"deep_network\", \"during_training\", \"encoder\", \"stack\", \"deep_convolutional\", \"recurrent_neural\", \"recurrent\", \"texture\", \"sentence\", \"feed_forward\", \"fully_connected\", \"analogy\", \"deep_learning\", \"pixel\", \"hidden_layer\", \"sequence_sequence\", \"deep_neural\", \"speech_recognition\", \"segmentation\", \"dropout\", \"unlabeled_data\", \"hidden_unit\", \"natural_image\", \"feature_map\", \"spatial\", \"answer\", \"semi_supervised\", \"frame\", \"proposal\", \"ground_truth\", \"embedding\", \"filter\", \"generative_model\"], \"Freq\": [1162.0, 904.0, 927.0, 661.0, 669.0, 742.0, 785.0, 567.0, 707.0, 533.0, 586.0, 473.0, 815.0, 576.0, 604.0, 474.0, 479.0, 573.0, 420.0, 493.0, 456.0, 897.0, 403.0, 496.0, 796.0, 403.0, 473.0, 472.0, 445.0, 676.0, 177.87413458151704, 119.49064728249881, 74.96236257452907, 78.82421570347739, 732.5354372614481, 77.7969882776182, 119.25512792379381, 90.24848392391043, 141.6789672916242, 41.904094558318675, 66.7107174745938, 25.39141368763215, 198.40965203904526, 261.0717706798568, 273.2573542633976, 42.64333276204647, 27.290959544201794, 686.1609311002574, 163.23024910585914, 554.5913527482467, 17.614043805550004, 18.57904923234067, 107.62726046930082, 17.587349164724614, 296.1142396149141, 13.730674251118668, 102.18482360734826, 471.8702867059895, 14.682985774682317, 10.83222220123276, 123.34362505971657, 325.22693554111527, 149.9736915841698, 62.67749665208074, 244.77098975857058, 164.12278176184566, 311.38017083667444, 345.12427294563565, 255.7029614224862, 185.34132315480983, 219.6620932717021, 593.5514330787635, 574.0163464546515, 554.5183924633437, 309.1021194045157, 168.95312335557585, 240.38973947947474, 294.46162984455754, 196.51771177315032, 672.0071103675239, 328.2876788100987, 285.0349237658774, 574.7869375612972, 267.89477332303085, 285.2159898387768, 520.6147564631252, 470.62376320428785, 311.2236621279619, 428.61420989269936, 360.5515768951021, 314.60442225633676, 335.9189093898135, 283.4369748918932, 259.9633082050752, 265.44814211063294, 401.86863312746976, 107.76159830246071, 74.40337884472059, 53.507957254930844, 71.53918087375918, 43.02750468580653, 84.83439343877755, 298.01808264633587, 215.96711226659474, 363.7879071816226, 448.74643774760716, 44.908717878626625, 57.223130608420625, 149.35173100721366, 136.06161987928726, 24.91881432047706, 365.09299462610335, 85.28115761862405, 36.27777578983569, 70.06136964550356, 23.01699468823585, 20.150409464828147, 177.5253495901045, 185.8881198776511, 39.06035400427754, 21.106867417481553, 100.6264292911789, 42.68590909169552, 172.94767730329477, 51.08380678744162, 206.789691677133, 209.54130844120365, 154.00091404798056, 210.55182026314597, 324.28698776147775, 159.52112215487216, 78.9861655164322, 850.9435309160665, 449.2445140980009, 402.96137648994835, 298.88066574042, 734.0917219975785, 128.74662521051238, 175.69752021741212, 304.6062390597894, 211.58676460232843, 455.61550984417767, 312.06573128680475, 253.00906132153548, 248.5266590198094, 432.71645351916965, 375.47584336741346, 563.319224962578, 456.7638252066534, 228.85725259957434, 300.1914243256274, 308.6733015162433, 412.2818056395146, 433.82678000746284, 268.12425688646005, 278.2763238645016, 255.53460932513318, 282.0076237151946, 241.82127313571883, 285.48209080914415, 278.06975450570513, 277.4598608692035, 271.4387667371746, 1158.0601223721997, 472.4330112760084, 264.55867575336316, 113.11856114591862, 295.1297734133653, 664.0344614042227, 67.93762982317247, 64.16999289128957, 347.26147675219426, 118.41064558861302, 50.980825367224675, 68.75531274767293, 41.577721890951885, 207.57725931051945, 53.7542117988099, 37.809687121434045, 34.04438597869567, 76.15811270684719, 31.216773071899752, 42.500216948729765, 33.10256264248704, 30.277689390313533, 99.39550154360933, 79.77655449778524, 26.508705235530503, 21.797510455629062, 25.566393644042623, 21.798761233041937, 20.856585268020517, 20.85782700366896, 267.9384631860818, 459.2408117469379, 122.12489391545579, 81.11292125275814, 164.97878249380284, 83.64987760017382, 83.6503357162383, 163.64413367407172, 541.4948760049302, 147.9304753818192, 439.6754944198721, 230.26268459586225, 356.6104441709007, 214.2864896316081, 451.4304150750833, 820.8969221405894, 360.68340943191293, 139.65265565596974, 354.80515342903743, 274.40850869877113, 672.814810341429, 452.3800173426236, 226.55454850177446, 461.74067877666, 376.7610891601341, 241.78150669826638, 282.5335828841761, 368.5804864854404, 371.85027783994155, 391.45856163158066, 238.46583140320237, 262.86863736877297, 286.46993311248764, 272.3699645459749, 268.54320050256, 248.60003386778996, 198.70016829221413, 470.82802361579974, 144.09700757316656, 110.2645372625228, 116.8286176802528, 253.82147672443935, 121.51555456421025, 155.2939010019173, 99.91037411149497, 83.91339552412968, 93.30891425055995, 655.6429165904433, 67.91907378082394, 330.1197030049469, 79.20763693711537, 107.35195905101031, 59.45080510782531, 75.42770529915525, 61.33054810241641, 195.2091784877974, 65.08191436299327, 79.10717035872526, 95.98855093344731, 80.06108066593806, 113.77550791146513, 188.2491422303327, 70.68731592618113, 82.78968246839379, 50.02332391614298, 70.6738595561603, 413.83039796847277, 212.8075856124486, 323.98371304192676, 393.1704113086583, 208.7722813369459, 192.20157362914415, 240.71071448765872, 515.5489868646187, 544.7587091847178, 201.3702564037946, 338.3064552357911, 182.7226541002052, 547.6722629113277, 232.5365177099513, 549.6033696449621, 410.5666228452266, 449.5356736398674, 160.68762726560468, 304.98894213012386, 219.10948200192612, 388.3830422762553, 192.9050118275981, 247.0468801486776, 436.4103360598659, 235.98141729517513, 267.53547454419254, 290.30828918532575, 290.79037726984205, 316.90872667603674, 266.4760192417587, 356.8554272247032, 407.63915942099175, 341.428975772925, 248.86012170524248, 293.792599580487], \"Total\": [1162.0, 904.0, 927.0, 661.0, 669.0, 742.0, 785.0, 567.0, 707.0, 533.0, 586.0, 473.0, 815.0, 576.0, 604.0, 474.0, 479.0, 573.0, 420.0, 493.0, 456.0, 897.0, 403.0, 496.0, 796.0, 403.0, 473.0, 472.0, 445.0, 676.0, 179.02430808486045, 120.60515505941852, 75.73633810423617, 79.70225092429746, 742.0682515169937, 78.81816816979354, 121.02879788165892, 91.64468353728913, 144.37240187556574, 42.721143397849495, 68.18817079141107, 26.040517327683894, 203.49234076601908, 267.865905201687, 280.71292068686574, 43.80842331438767, 28.07466116387381, 707.2591002063504, 168.3261411375686, 573.2734548673467, 18.268434038634965, 19.279580028138913, 111.74338836016726, 18.3103001350113, 308.8004768341181, 14.325468722521025, 106.85628171235571, 493.88756160733635, 15.3716873161234, 11.341916656687104, 129.32392626764525, 344.77079780709204, 158.03772179601165, 65.66433402592236, 261.4442374442859, 174.32270788236022, 336.41303587780686, 374.8186872165383, 275.77633096916566, 198.38497770593608, 238.5056003403269, 676.5933807864516, 659.2056275952971, 668.9401923153032, 354.918307827253, 184.1303822164176, 271.9623729356517, 342.22223222853944, 218.68210037075815, 897.3642355175849, 394.3204752926572, 335.73916426596406, 775.0020954340171, 313.7428226866048, 342.8665944967438, 751.251821958462, 663.165256736406, 402.25055077947746, 705.4699920562456, 599.2074979968014, 476.85349212602705, 644.7807170419604, 427.7299818118475, 343.38009252166285, 724.0678225664151, 403.57498651146057, 108.75905639033296, 75.34578815351976, 54.19098763670324, 72.47452566995477, 43.606324657523736, 86.05199969658382, 302.4810732915092, 219.31545586935638, 369.8523612215477, 456.53488146987337, 45.70137316712675, 58.306294851360356, 152.4522572210644, 138.97969855366782, 25.478926074170595, 373.40406486774856, 87.29027469391666, 37.150264621148196, 71.80354527680603, 23.598146366425723, 20.661704481299967, 182.04339725512048, 190.86365517008892, 40.12110861833261, 21.682851411233333, 103.43517738329732, 43.93159614091472, 178.21822414011982, 52.66664144141134, 213.64875593046472, 216.54093948924384, 159.02686980565323, 218.1324283774869, 337.89577740879554, 165.38529150480127, 81.51990442379717, 904.5351743569287, 472.75187490988014, 424.78391821177394, 313.7436305801843, 785.4421784906534, 134.17991851080393, 184.97068791674337, 333.2847693938301, 227.28453012490473, 514.5425936561102, 346.6471698356796, 279.6865354523888, 275.6142230305134, 516.4302611274243, 460.4304527290996, 796.3566951070738, 668.5043228700155, 275.34411920759834, 414.3734528025643, 438.77867802531, 724.0678225664151, 795.3447530234967, 360.0466461456365, 414.41030793253435, 349.5557747029994, 469.9645624931151, 315.56866535815647, 505.3599059491185, 480.4900897065831, 483.57662292273216, 538.9548760535442, 1162.5179194366915, 474.2842870163904, 265.8854364580018, 113.9050938383165, 297.32308335940024, 669.72429105886, 68.584865773023, 64.89206308489634, 351.4452993186657, 119.84391864945961, 51.679607631019486, 69.74055237089841, 42.17433838482122, 210.848521465978, 54.613769959497795, 38.427715953950084, 34.62170517371208, 77.45317425294499, 31.756285016346126, 43.23807093122085, 33.68537119234875, 30.840548073963774, 101.28913016490422, 81.3466314697008, 27.041990828390652, 22.29592786169811, 26.155628800920674, 22.319421910660576, 21.360205610080392, 21.369165479660232, 276.1697659486563, 479.25084701010263, 125.88296100750168, 83.2856372666328, 170.80332706263897, 86.04746540151633, 86.05380057425347, 169.86263609229474, 576.7484717814194, 153.69054066303417, 473.0146606607841, 243.3973538523455, 382.26350136790967, 226.87393665283662, 496.792631205753, 927.5368368534172, 406.66514949129396, 148.5088380769613, 404.8733179831965, 308.34674909555577, 815.784879057702, 530.0398376414162, 253.91648423597726, 555.3267820578599, 525.5502913742517, 301.0293628774831, 377.59523510938783, 562.4378574912739, 595.7091492649519, 781.9073149777149, 348.22348593625577, 456.8771003172615, 623.8008951900446, 640.5833374555011, 675.0780559215312, 459.54235664127765, 199.69810931923843, 473.4406909275641, 145.14980476911188, 111.0785951023486, 117.71981059896532, 255.76150492367609, 122.46317665345286, 156.58537434134806, 100.74440340637601, 84.62377884042039, 94.14791941470149, 661.8544031692505, 68.59667770104345, 333.43483026119964, 80.00369156254908, 108.47424686564139, 60.11529469244895, 76.2861057199509, 62.033591505220485, 197.49683472013575, 65.87021231476993, 80.079369029592, 97.17557015479068, 81.09983082927403, 115.27403354854984, 190.75288567874404, 71.66130560908304, 83.94754734805335, 50.727358091448224, 71.69083456256737, 420.68602049608114, 216.3390061417959, 330.9687682936702, 403.0092801921183, 212.85738056073546, 195.85960060266706, 245.93247886010485, 533.5232671183153, 567.6022642578647, 206.4015911889938, 351.2161154462733, 187.67977450961106, 586.1004820085063, 242.09246906560318, 604.8215513806447, 445.5847658037037, 493.69008661502335, 167.33637830611875, 337.6718928768084, 235.10064724527973, 441.32604778568793, 204.6397490950366, 272.99814010024846, 542.1933424329312, 263.20806980828985, 311.28469942825365, 368.189632696188, 372.6821207415605, 438.20153892123403, 334.7489917625468, 579.0670080482574, 797.0639759013595, 619.3987854860638, 376.96316361747483, 795.3447530234967], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.5739, -6.9717, -7.438, -7.3877, -5.1584, -7.4009, -6.9737, -7.2524, -6.8014, -8.0196, -7.5546, -8.5205, -6.4646, -6.1902, -6.1445, -8.0021, -8.4484, -5.2238, -6.6598, -5.4367, -8.8863, -8.8329, -7.0763, -8.8878, -6.0642, -9.1353, -7.1282, -5.5982, -9.0683, -9.3724, -6.94, -5.9704, -6.7445, -7.617, -6.2546, -6.6543, -6.0139, -5.911, -6.2109, -6.5328, -6.3629, -5.3688, -5.4023, -5.4369, -6.0213, -6.6253, -6.2727, -6.0698, -6.4742, -5.2447, -5.9611, -6.1023, -5.401, -6.1644, -6.1017, -5.4999, -5.6009, -6.0144, -5.6944, -5.8673, -6.0036, -5.9381, -6.108, -6.1944, -6.1735, -5.6231, -6.9394, -7.3098, -7.6394, -7.349, -7.8574, -7.1786, -5.9221, -6.2441, -5.7227, -5.5128, -7.8146, -7.5723, -6.613, -6.7062, -8.4036, -5.7191, -7.1733, -8.0281, -7.3699, -8.483, -8.616, -6.4402, -6.3941, -7.9542, -8.5697, -7.0079, -7.8654, -6.4663, -7.6858, -6.2876, -6.2744, -6.5823, -6.2695, -5.8376, -6.5471, -7.25, -4.8729, -5.5117, -5.6204, -5.9192, -5.0206, -6.7614, -6.4505, -5.9003, -6.2646, -5.4976, -5.8761, -6.0858, -6.1037, -5.5492, -5.6911, -5.2854, -5.4951, -6.1862, -5.9149, -5.887, -5.5976, -5.5466, -6.0278, -5.9907, -6.0759, -5.9773, -6.1311, -5.9651, -5.9914, -5.9936, -6.0155, -4.4934, -5.39, -5.9698, -6.8194, -5.8605, -5.0495, -7.3293, -7.3863, -5.6978, -6.7737, -7.6164, -7.3173, -7.8203, -6.2124, -7.5635, -7.9153, -8.0202, -7.2151, -8.1069, -7.7984, -8.0483, -8.1375, -6.9488, -7.1687, -8.2704, -8.4661, -8.3066, -8.466, -8.5102, -8.5102, -5.9571, -5.4183, -6.7428, -7.152, -6.4421, -7.1212, -7.1212, -6.4502, -5.2535, -6.5511, -5.4618, -6.1087, -5.6712, -6.1806, -5.4355, -4.8375, -5.6599, -6.6087, -5.6763, -5.9333, -5.0364, -5.4334, -6.1249, -5.4129, -5.6163, -6.0598, -5.9041, -5.6382, -5.6294, -5.578, -6.0737, -5.9762, -5.8902, -5.9407, -5.9549, -6.032, -6.2069, -5.3442, -6.5282, -6.7958, -6.738, -5.962, -6.6986, -6.4533, -6.8944, -7.0689, -6.9627, -5.013, -7.2803, -5.6992, -7.1266, -6.8225, -7.4135, -7.1755, -7.3824, -6.2246, -7.323, -7.1279, -6.9344, -7.1159, -6.7644, -6.2609, -7.2404, -7.0824, -7.5862, -7.2406, -5.4732, -6.1383, -5.718, -5.5244, -6.1574, -6.2401, -6.0151, -5.2534, -5.1983, -6.1935, -5.6747, -6.2907, -5.193, -6.0496, -5.1895, -5.4811, -5.3904, -6.4192, -5.7784, -6.1091, -5.5367, -6.2365, -5.9891, -5.4201, -6.0349, -5.9094, -5.8277, -5.8261, -5.74, -5.9134, -5.6213, -5.4883, -5.6655, -5.9818, -5.8158], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2348, 1.232, 1.231, 1.2302, 1.2283, 1.2282, 1.2265, 1.2259, 1.2224, 1.222, 1.2194, 1.216, 1.216, 1.2156, 1.2144, 1.2143, 1.213, 1.211, 1.2105, 1.2081, 1.2048, 1.2043, 1.2037, 1.201, 1.1993, 1.1989, 1.1966, 1.1957, 1.1954, 1.1953, 1.1939, 1.1829, 1.1889, 1.1947, 1.1754, 1.181, 1.1639, 1.1587, 1.1657, 1.1733, 1.159, 1.1103, 1.1029, 1.0537, 1.1031, 1.1552, 1.1179, 1.091, 1.1344, 0.9521, 1.058, 1.0775, 0.9424, 1.0833, 1.0572, 0.8745, 0.8983, 0.9847, 0.743, 0.7333, 0.8254, 0.5892, 0.8298, 0.963, 0.2378, 1.3727, 1.3677, 1.3644, 1.3643, 1.364, 1.3636, 1.3627, 1.3621, 1.3616, 1.3604, 1.3597, 1.3595, 1.3582, 1.3564, 1.3557, 1.3547, 1.3544, 1.3537, 1.3532, 1.3524, 1.352, 1.3519, 1.3518, 1.3505, 1.3502, 1.35, 1.3494, 1.3482, 1.3469, 1.3464, 1.3443, 1.3441, 1.3448, 1.3416, 1.3358, 1.3408, 1.3454, 1.3159, 1.3259, 1.3242, 1.3284, 1.3093, 1.3356, 1.3255, 1.287, 1.3054, 1.2553, 1.2719, 1.2767, 1.2735, 1.2001, 1.173, 1.0307, 0.9961, 1.192, 1.0546, 1.0252, 0.8138, 0.7708, 1.0822, 0.9787, 1.0636, 0.8662, 1.1108, 0.8059, 0.83, 0.8214, 0.6911, 1.4445, 1.4444, 1.4433, 1.4414, 1.4409, 1.4398, 1.4389, 1.4371, 1.4364, 1.4363, 1.4347, 1.4341, 1.4341, 1.4327, 1.4325, 1.4321, 1.4315, 1.4315, 1.4312, 1.4311, 1.4309, 1.4299, 1.4295, 1.4288, 1.4284, 1.4257, 1.4256, 1.4247, 1.4245, 1.4241, 1.4181, 1.4057, 1.418, 1.4219, 1.4136, 1.4201, 1.42, 1.411, 1.3853, 1.4101, 1.3752, 1.3929, 1.3789, 1.3913, 1.3526, 1.3262, 1.3283, 1.3869, 1.3163, 1.3317, 1.2557, 1.2899, 1.3343, 1.2638, 1.1155, 1.2292, 1.1583, 1.0257, 0.9771, 0.7565, 1.0697, 0.8956, 0.6701, 0.5931, 0.5265, 0.834, 1.4926, 1.492, 1.4903, 1.4902, 1.49, 1.4899, 1.4898, 1.4893, 1.4892, 1.4891, 1.4886, 1.4881, 1.4876, 1.4876, 1.4876, 1.4872, 1.4864, 1.4862, 1.4862, 1.4859, 1.4855, 1.4853, 1.4853, 1.4847, 1.4845, 1.4843, 1.4839, 1.4837, 1.4836, 1.4833, 1.4811, 1.4811, 1.4762, 1.4728, 1.4782, 1.4787, 1.4761, 1.4633, 1.4565, 1.4729, 1.4601, 1.4708, 1.4297, 1.4573, 1.4018, 1.4157, 1.4039, 1.457, 1.3958, 1.4271, 1.3698, 1.4385, 1.3977, 1.2805, 1.3884, 1.3461, 1.2599, 1.2494, 1.1735, 1.2695, 1.0135, 0.827, 0.902, 1.0823, 0.5017]}, \"token.table\": {\"Topic\": [3, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 3, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 3, 1, 3, 3, 3, 1, 2, 3, 4, 2, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 2, 3, 3, 1, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 1, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 3, 4, 3, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 2, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 4, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 2, 1, 2, 3, 4, 2, 2, 2, 1, 2, 3, 4, 4, 4, 2, 4, 4, 1, 2, 1, 3], \"Freq\": [0.9868495977006689, 0.9720568883328328, 0.8296705839711336, 0.05531137226474224, 0.09417882304537192, 0.02092862734341598, 0.008511280039457442, 0.6000452427817496, 0.3638572216868056, 0.027661660128236683, 0.917827888943205, 0.04887840828691624, 0.02172373701640722, 0.01086186850820361, 0.00826130613529342, 0.02478391840588026, 0.00826130613529342, 0.9624421647616834, 0.14489560135740118, 0.029515770646878017, 0.04293203003182257, 0.780826296203773, 0.004680579559870994, 0.9688799688932958, 0.004680579559870994, 0.02340289779935497, 0.005887109861268436, 0.011774219722536871, 0.9654860172480234, 0.023548439445073743, 0.017564060674882552, 0.017564060674882552, 0.9660233371185404, 0.005854686891627518, 0.9938853911223363, 0.0029863035083256763, 0.0029863035083256763, 0.9914527647641246, 0.0029863035083256763, 0.9920539652107109, 0.0037610183292530806, 0.9966698572520664, 0.009872727689258912, 0.009872727689258912, 0.9774000412366323, 0.060008742782862515, 0.9151333274386533, 0.015002185695715629, 0.012001748556572503, 0.8706228819010303, 0.11833709074382937, 0.002817549779614985, 0.00563509955922997, 0.9930207523352471, 0.12307738262446043, 0.7239846036732966, 0.04585235823264212, 0.10618440853875016, 0.9825751185635159, 0.014665300277067401, 0.02324298560878652, 0.9762053955690337, 0.9856886118314736, 0.9820429071707267, 0.9407839173234598, 0.005736487300752803, 0.045891898406022424, 0.005736487300752803, 0.9860954881594425, 0.9846531270611526, 0.9862531249202344, 0.9984471990743164, 0.9491404855456825, 0.02531041294788487, 0.01898280971091365, 0.012655206473942434, 0.8488732633355525, 0.04169903749718503, 0.07744106963762934, 0.032763529462073955, 0.023241274489373128, 0.9761335285536714, 0.9511001061431013, 0.023197563564465885, 0.01546504237631059, 0.007732521188155295, 0.2592211975225228, 0.5639545136940382, 0.1602818091551477, 0.01780908990612752, 0.9426552424600813, 0.005800955338215885, 0.017402866014647654, 0.03480573202929531, 0.9743681257362061, 0.007466422419434529, 0.014932844838869058, 0.0037332112097172646, 0.9679743516853196, 0.08301557085453917, 0.028031231717117126, 0.8851400476828138, 0.004312497187248789, 0.983338196610243, 0.003021812637980678, 0.004532718956971017, 0.001510906318990339, 0.9911545452576623, 0.9965041766213097, 0.0029990868057084485, 0.005998173611416897, 0.0029990868057084485, 0.9896986458837881, 0.011885348588726344, 0.002377069717745269, 0.002377069717745269, 0.9841068631465413, 0.07459134908171958, 0.02918791920589027, 0.8886099847126593, 0.006486204267975615, 0.9683548941835338, 0.018987350866343802, 0.3659878145954938, 0.5690074702390319, 0.05248127152690099, 0.011048688742505471, 0.012006872166908851, 0.972556645519617, 0.988761626235417, 0.9815463955736073, 0.022826660362176916, 0.9896195485280627, 0.7419334778417447, 0.16516084376303186, 0.06709659277873169, 0.02580638183797373, 0.07626819871960602, 0.8316865479423704, 0.08716365567954974, 0.007263637973295812, 0.9325302860089715, 0.015122112746091428, 0.04032563398957714, 0.015122112746091428, 0.8824750181775542, 0.007353958484812952, 0.06618562636331657, 0.04412375090887771, 0.004066156713562163, 0.016264626854248652, 0.004066156713562163, 0.9799437679684813, 0.029760844267058356, 0.024800703555881962, 0.036374365215293546, 0.9093591303823386, 0.0030214331254141027, 0.015107165627070514, 0.0030214331254141027, 0.9789443326341692, 0.005922909315788545, 0.03849891055262554, 0.053306183842096906, 0.9032436706577531, 0.021998857543239915, 0.9327515598333723, 0.03959794357783185, 0.0043997715086479825, 0.007452680036614285, 0.9613957247232428, 0.02981072014645714, 0.1465799893647339, 0.5028250268081379, 0.07236227323069143, 0.2764609925993083, 0.004886636171233727, 0.034206453198636085, 0.014659908513701178, 0.9431207810481091, 0.032532906569458155, 0.006506581313891631, 0.9629740344559614, 0.006506581313891631, 0.012406662193030526, 0.007443997315818315, 0.00496266487721221, 0.9751636483721994, 0.030854139101537375, 0.008815468314724965, 0.9432551096755712, 0.01763093662944993, 0.9665001355775815, 0.008949075329422051, 0.017898150658844102, 0.008949075329422051, 0.4020027256020546, 0.040361719437957286, 0.006457875110073166, 0.5505338531337374, 0.2409988038478231, 0.005296677007644464, 0.7494797965816916, 0.005296677007644464, 0.004697981330812562, 0.009395962661625124, 0.004697981330812562, 0.9818780981398255, 0.9962178291784513, 0.8318107238954929, 0.030432099654713156, 0.12680041522797147, 0.010144033218237718, 0.9942783854560414, 0.008344186432396077, 0.984613999022737, 0.10642215281279364, 0.8144552511183187, 0.0738439427680609, 0.0065156420089465495, 0.13492471707457102, 0.0032124932636802624, 0.0032124932636802624, 0.8609481946663102, 0.010656449290957456, 0.010656449290957456, 0.005328224645478728, 0.9750651101226072, 0.021222232759373905, 0.2918057004413912, 0.02918057004413912, 0.6605419946355128, 0.9761847137989585, 0.026885816601306223, 0.17326415143064008, 0.0029873129557006915, 0.7946252462163839, 0.9282885122894146, 0.02538288900791368, 0.014504508004522102, 0.029009016009044205, 0.9690884767148774, 0.024533885486452592, 0.030711457425040573, 0.02218049702919597, 0.011943344554182445, 0.9349932593845686, 0.03207306091490595, 0.003773301284106582, 0.8527660902080876, 0.10942573723909088, 0.9940498925831522, 0.011055402026913339, 0.9408147124903252, 0.03648282668881402, 0.011055402026913339, 0.05909387070365383, 0.5456753167103354, 0.02640364435695171, 0.36965102099732394, 0.01647896659899018, 0.9487176484847205, 0.021187242770130232, 0.014124828513420156, 0.009917975916161932, 0.9851856076720852, 0.003305991972053977, 0.003305991972053977, 0.006571239398709492, 0.9834954966735207, 0.002190413132903164, 0.008761652531612657, 0.23915878060985998, 0.03708879485393551, 0.5000592685478891, 0.22381169308409354, 0.6935091333845803, 0.2715467624001044, 0.017304450545104693, 0.01863556212549736, 0.25780625907147375, 0.039115432410844295, 0.6560724799818883, 0.04800530341330891, 0.10867596861946367, 0.0024699083777150834, 0.8768174740888547, 0.009879633510860334, 0.14427951014841975, 0.297341251349352, 0.04767496857078218, 0.5118786099178718, 0.9758200054112774, 0.009667890801736854, 0.9764569709754223, 0.01933578160347371, 0.0071952955029172426, 0.978560188396745, 0.0071952955029172426, 0.004051124489278206, 0.08304805203020324, 0.004051124489278206, 0.9115030100875965, 0.050795636908948824, 0.9034366850234469, 0.00725651955842126, 0.03991085757131693, 0.0055330815877199695, 0.180747331865519, 0.009221802646199949, 0.8041411907486355, 0.9864385558141383, 0.9865212595619586, 0.9902776114786175, 0.985498645316399, 0.9874544343773891, 0.9856614237599958, 0.2769808054880376, 0.08225490587220512, 0.6244658160093939, 0.016786715484123492, 0.02693442391574764, 0.02693442391574764, 0.9427048370511674, 0.00673360597893691, 0.990363697580275, 0.9907717895527817, 0.8542028075896514, 0.006374647817833219, 0.1370549280834142, 0.0031873239089166097, 0.01311886118616064, 0.9773551583689677, 0.00655943059308032, 0.00655943059308032, 0.005406261993522493, 0.9515021108599588, 0.005406261993522493, 0.04325009594817995, 0.6605802520090364, 0.0964656875949704, 0.21809633717123741, 0.025164961981296623, 0.012684596269422645, 0.03805378880826793, 0.9302037264243272, 0.019026894404133965, 0.02875955670515004, 0.02465104860441432, 0.9449568631692156, 0.0041085081007357195, 0.9866908254574382, 0.008291519541659145, 0.29192142390527004, 0.15454663618514297, 0.42461298022584737, 0.12956940205421077, 0.0021121969850981795, 0.0021121969850981795, 0.0021121969850981795, 0.9948447799812427, 0.010290652253514982, 0.9879026163374384, 0.005063372288558735, 0.005063372288558735, 0.005063372288558735, 0.9873575962689534, 0.00956194710455893, 0.9530073947543735, 0.031873157015196434, 0.006374631403039287, 0.014301725299468063, 0.9045841251913549, 0.0679331951724733, 0.014301725299468063, 0.015068624491675234, 0.7069696324010964, 0.268723803434875, 0.00879003095347722, 0.9748822252459363, 0.013926888932084804, 0.9853061276041906, 0.9877797608259676, 0.0013475849397352902, 0.009433094578147031, 0.0013475849397352902, 0.002703781575700103, 0.9841764935548376, 0.005407563151400206, 0.005407563151400206, 0.9600423711022933, 0.026635431993314182, 0.9588755517593105, 0.0029594924437015757, 0.008878477331104728, 0.9934525177561597, 0.05481077491273483, 0.9000506196196457, 0.017308665761916264, 0.028847776269860438, 0.003363344644153354, 0.9921866700252394, 0.003363344644153354, 0.9888695972859111, 0.8312270853283918, 0.04083220770034206, 0.06999807034344353, 0.055415139021892795, 0.9827243848145771, 0.9958662449371354, 0.0037992756100842947, 0.09498189025210736, 0.0037992756100842947, 0.8966290439798935, 0.9698537145848702, 0.9830532469307823, 0.010339623056590393, 0.5728151173351078, 0.004135849222636157, 0.41151699765229766, 0.9831366038016787, 0.9204450358706059, 0.02401160963140711, 0.04802321926281422, 0.005335913251423802, 0.003909892539529818, 0.003909892539529818, 0.9931127050405738, 0.9920784959308704, 0.02521038144085284, 0.11164597495234829, 0.8319425875481437, 0.030612606035321305, 0.0046180643824613715, 0.9697935203168879, 0.02770838629476823, 0.0046180643824613715, 0.3808464024114408, 0.028454041559475465, 0.5756471484724651, 0.01751017942121567, 0.9224102062428681, 0.05450605764162402, 0.008385547329480618, 0.016771094658961237, 0.9926287995056723, 0.013753113291382702, 0.9673023014939166, 0.013753113291382702, 0.004584371097127567, 0.01048476930183009, 0.9855683143720284, 0.9796537438036479, 0.020198177071351735, 0.04712907983315404, 0.011221209484084296, 0.9223834195917292, 0.005690786030933768, 0.002845393015466884, 0.9873513763670089, 0.002845393015466884, 0.010478684368785098, 0.9745176462970142, 0.005239342184392549, 0.010478684368785098, 0.25174809391940195, 0.7323580914018967, 0.011443095178154635, 0.005721547589077318, 0.011456029935826183, 0.9737625445452256, 0.011456029935826183, 0.011967013116167277, 0.6836156242610557, 0.2797289315904101, 0.023934026232334555, 0.6616323662915166, 0.12858579556902267, 0.198723502243035, 0.009351694223201647, 0.9902898024470441, 0.1471971107676471, 0.6708327343181294, 0.16650164988471555, 0.014478404337801353, 0.004230549059972013, 0.9497582639637169, 0.010576372649930032, 0.03595966700976211, 0.9690375120371715, 0.004559642164917406, 0.9848827076221597, 0.004559642164917406, 0.009119284329834812, 0.987774837304268, 0.0060464869088492626, 0.9674379054158819, 0.02418594763539705, 0.0060464869088492626, 0.09451926712129333, 0.00787660559344111, 0.893994734855566, 0.003938302796720555, 0.025346728219704524, 0.0036209611742435035, 0.970417594697259, 0.0036209611742435035, 0.7571784318964192, 0.2067679564024837, 0.008736674214189452, 0.026210022642568356, 0.9725238130543001, 0.021374149737457146, 0.003562358289576191, 0.003562358289576191, 0.937102314416893, 0.026774351840482657, 0.03442416665204913, 0.0038249074057832367, 0.6024624211259904, 0.011682096808537209, 0.38217145273643155, 0.005006612917944519, 0.005180747578957201, 0.37128690982526613, 0.008634579298262002, 0.616508961895907, 0.005493195661464026, 0.9777888277405966, 0.005493195661464026, 0.01647958698439208, 0.04982902616747356, 0.13952127326892597, 0.8039082888352401, 0.006643870155663142, 0.7102302106686093, 0.03166631512535201, 0.06484055001857791, 0.19452165005573374, 0.36550123886971736, 0.16191063651684848, 0.4584796241962244, 0.01442768048169937, 0.9244588254093772, 0.03269790057718054, 0.017835218496643934, 0.023780291328858578, 0.9699415671001649, 0.0028278179798838627, 0.008483453939651588, 0.018380816869245108, 0.12635563589773047, 0.0775364129372437, 0.6834691214468148, 0.10912532191167632, 0.9556831082441027, 0.01619801878379835, 0.01619801878379835, 0.012148514087848764, 0.001761797059262073, 0.035235941185241454, 0.001761797059262073, 0.9601793972978298, 0.9878072779320257, 0.9913016530677495, 0.004622374937530064, 0.013867124812590193, 0.9845658616939037, 0.0018743325017505522, 0.029989320028008835, 0.0018743325017505522, 0.967155570903285, 0.000860201794123362, 0.000860201794123362, 0.9961136775948531, 0.001720403588246724, 0.0021084400798743767, 0.0021084400798743767, 0.9951837177007058, 0.0021084400798743767, 0.9914723785425407, 0.9893813234090839, 0.009116213253573978, 0.7042274738385897, 0.18004521175808605, 0.10711550572949424, 0.8590908839717457, 0.07889610158924196, 0.02629870052974732, 0.0321428562030245, 0.9831410227614418, 0.9911890703693618, 0.003805534946560941, 0.2701929812058268, 0.7173433374267374, 0.009513837366402352, 0.0024590255674746685, 0.10819712496888541, 0.8877082298583553, 0.0024590255674746685, 0.99449395113858, 0.011912200315441246, 0.9887126261816234, 0.07447775525614826, 0.00603873691266067, 0.9078234492033208, 0.010064561521101117, 0.6081052416554051, 0.14600195778672898, 0.1332445051645876, 0.11339957886347882, 0.7488597978416216, 0.006686248195014479, 0.24070493502052123, 0.004457498796676319, 0.5211073953040288, 0.23108631517946515, 0.23884088951434654, 0.010856404068833933, 0.0026780640439845716, 0.9774933760543686, 0.0026780640439845716, 0.01606838426390743, 0.9831197542834073, 0.04305207022184781, 0.058913359250949635, 0.018127187461830657, 0.8791685918987869, 0.006386292488722807, 0.989875335752035, 0.2441798818493722, 0.01597438479388416, 0.01597438479388416, 0.7234114256658971, 0.9545531471380575, 0.028075092562884044, 0.009358364187628015, 0.009358364187628015, 0.017083498552952478, 0.014236248794127064, 0.005694499517650825, 0.9623704184829895, 0.023903947488827286, 0.0059759868722068215, 0.011951973744413643, 0.9621338864252983, 0.958547742654574, 0.016191684842138076, 0.01295334787371046, 0.01295334787371046, 0.9681243659335751, 0.00697747290762937, 0.008721841134536713, 0.017443682269073425, 0.9730095946346485, 0.00982837974378433, 0.00982837974378433, 0.004914189871892165, 0.9594249440667356, 0.01522896736613866, 0.01522896736613866, 0.9814474053873508, 0.9835674835027646, 0.01385306314792626, 0.04345586778974413, 0.1602435124746815, 0.008147975210577025, 0.7876376036891124, 0.900851051210877, 0.013718543927069194, 0.08231126356241517, 0.004572847975689731, 0.008506994869790412, 0.05104196921874247, 0.008506994869790412, 0.9315159382420501, 0.9775959893405939, 0.010211396295335679, 0.005105698147667839, 0.005105698147667839, 0.9802940443522251, 0.029045548119611242, 0.8384481557194444, 0.11037308285452271, 0.021300068621048242, 0.006337764865627861, 0.7668695487409712, 0.22499065272978908, 0.0031688824328139306, 0.9832370649203451, 0.008262496343868447, 0.008262496343868447, 0.03309696059969535, 0.10909738864344022, 0.8249723882812952, 0.03309696059969535, 0.9867272686055608, 0.9727453587417475, 0.032641169596710574, 0.3111791501553075, 0.5418434153053956, 0.11533213257504403, 0.006288245509844343, 0.968389808516029, 0.006288245509844343, 0.025152982039377374, 0.009485482687260462, 0.004742741343630231, 0.986490199475088, 0.027125669325579638, 0.012519539688729063, 0.9577447861877733, 0.0020865899481215104, 0.03120944550473257, 0.005201574250788762, 0.9380172232255733, 0.024274013170347556, 0.04708793786377186, 0.005231993095974651, 0.9339107676314752, 0.01831197583591128, 0.9691541970698458, 0.023831660583684734, 0.7731499668486396, 0.17402089285982242, 0.0372901913271048, 0.014916076530841921, 0.9772804137284976, 0.9617213131228571, 0.008674980559076482, 0.9889477837347189, 0.8779275956107528, 0.01921390360764274, 0.005911970340813151, 0.09754751062341699, 0.9683582056739738, 0.011881695775140783, 0.005940847887570391, 0.017822543662711174, 0.014534771668756266, 0.009689847779170844, 0.004844923889585422, 0.9738297018066698, 0.043705375927365946, 0.5785759289432254, 0.27263829745166374, 0.10406041887468082, 0.02221965277707612, 0.2799676249911591, 0.39847243980223174, 0.2992246573979584, 0.9746528241185615, 0.0024778542610980237, 0.9960974129614055, 0.0024778542610980237, 0.007773894813212224, 0.8862240087061936, 0.05830421109909168, 0.05053031628587946, 0.12498380552001531, 0.7443479973192023, 0.09720962651556746, 0.03332901480533742, 0.005611098443073778, 0.9707200306517637, 0.022444393772295113, 0.005611098443073778, 0.08791268684536417, 0.0036630286185568408, 0.0073260572371136815, 0.9047680687835397, 0.012911026689935528, 0.9812380284351001, 0.9821385085151983, 0.01909752291228462, 0.9345054545077941, 0.010185345553218464, 0.03564870943626462, 0.9812030509929495, 0.996475656838299, 0.9685073056913739, 0.8707449936279869, 0.0060679093632612325, 0.10770539119788687, 0.01516977340815308, 0.9926109701263177, 0.9864092454362239, 0.9787943934946834, 0.022762660313829848, 0.9867889857313424, 0.982053693964474, 0.010911707710716378, 0.012293072029325152, 0.9834457623460121], \"Term\": [\"accelerated_proximal\", \"acceptance\", \"active_learning\", \"active_learning\", \"active_learning\", \"active_learning\", \"agent\", \"agent\", \"agent\", \"agent\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"alternating_minimization\", \"analogy\", \"analogy\", \"analogy\", \"analogy\", \"answer\", \"answer\", \"answer\", \"answer\", \"approximate_posterior\", \"approximate_posterior\", \"approximate_posterior\", \"approximate_posterior\", \"arm\", \"arm\", \"arm\", \"arm\", \"armed\", \"armed\", \"armed\", \"armed\", \"autoencoder\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit_feedback\", \"bandit_problem\", \"bandit_problem\", \"bandit_setting\", \"bandit_setting\", \"bandit_setting\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_network\", \"bayesian_network\", \"bayesian_network\", \"bayesian_network\", \"bayesian_nonparametric\", \"belief\", \"belief\", \"belief\", \"belief\", \"benjamin_recht\", \"benjamin_recht\", \"bianchi\", \"bianchi\", \"bianchi_lugosi\", \"bianchi_regret\", \"bipartite_graph\", \"bipartite_graph\", \"bipartite_graph\", \"bipartite_graph\", \"black_variational\", \"blei_jordan\", \"bubeck\", \"bubeck_cesa\", \"calibration\", \"calibration\", \"calibration\", \"calibration\", \"causal\", \"causal\", \"causal\", \"causal\", \"cesa\", \"cesa\", \"clique\", \"clique\", \"clique\", \"clique\", \"closed_form\", \"closed_form\", \"closed_form\", \"closed_form\", \"completion\", \"completion\", \"completion\", \"completion\", \"compressed_sensing\", \"compressed_sensing\", \"compressed_sensing\", \"compressed_sensing\", \"conjugacy\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convnets\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional_layer\", \"convolutional_network\", \"convolutional_network\", \"convolutional_network\", \"convolutional_network\", \"convolutional_neural\", \"convolutional_neural\", \"convolutional_neural\", \"convolutional_neural\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"covariance_function\", \"covariance_function\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"cumulative_regret\", \"cumulative_regret\", \"current_iterate\", \"dantzig\", \"dantzig\", \"dantzig_selector\", \"data_set\", \"data_set\", \"data_set\", \"data_set\", \"decision_making\", \"decision_making\", \"decision_making\", \"decision_making\", \"decision_rule\", \"decision_rule\", \"decision_rule\", \"decision_rule\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"deep_convolutional\", \"deep_convolutional\", \"deep_convolutional\", \"deep_convolutional\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_network\", \"deep_network\", \"deep_network\", \"deep_network\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"dirichlet\", \"dirichlet\", \"dirichlet\", \"dirichlet\", \"dirichlet_process\", \"dirichlet_process\", \"dirichlet_process\", \"document\", \"document\", \"document\", \"document\", \"dropout\", \"dropout\", \"dropout\", \"dropout\", \"dual_variable\", \"dual_variable\", \"dual_variable\", \"dual_variable\", \"during_training\", \"during_training\", \"during_training\", \"during_training\", \"each_round\", \"each_round\", \"each_round\", \"each_round\", \"edge_weight\", \"edge_weight\", \"edge_weight\", \"edge_weight\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder_decoder\", \"estimation_error\", \"estimation_error\", \"estimation_error\", \"estimation_error\", \"exact_recovery\", \"expected_reward\", \"expected_reward\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"feature_map\", \"feature_map\", \"feature_map\", \"feature_map\", \"feed_forward\", \"feed_forward\", \"feed_forward\", \"feed_forward\", \"filter\", \"filter\", \"filter\", \"filter\", \"fischer_finite\", \"frame\", \"frame\", \"frame\", \"frame\", \"frobenius_norm\", \"frobenius_norm\", \"frobenius_norm\", \"frobenius_norm\", \"full_posterior\", \"full_posterior\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"game\", \"game\", \"game\", \"game\", \"game_cambridge\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs_sampler\", \"gibbs_sampler\", \"gibbs_sampler\", \"gibbs_sampler\", \"gibbs_sampling\", \"gibbs_sampling\", \"gibbs_sampling\", \"gibbs_sampling\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"greedy\", \"greedy\", \"greedy\", \"greedy\", \"greedy_algorithm\", \"greedy_algorithm\", \"greedy_algorithm\", \"greedy_algorithm\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"halko\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian\", \"hamiltonian_monte\", \"hamiltonian_monte\", \"hamiltonian_monte\", \"hidden_layer\", \"hidden_layer\", \"hidden_layer\", \"hidden_layer\", \"hidden_markov\", \"hidden_markov\", \"hidden_markov\", \"hidden_markov\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"ilya_sutskever\", \"image_caption\", \"incoherence\", \"incoherent\", \"input_image\", \"input_sequence\", \"item\", \"item\", \"item\", \"item\", \"iteration_complexity\", \"iteration_complexity\", \"iteration_complexity\", \"iteration_complexity\", \"krizhevsky\", \"krizhevsky_sutskever\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"latent_dirichlet\", \"latent_dirichlet\", \"latent_dirichlet\", \"latent_dirichlet\", \"latent_state\", \"latent_state\", \"latent_state\", \"latent_state\", \"least_square\", \"least_square\", \"least_square\", \"least_square\", \"line_search\", \"line_search\", \"line_search\", \"line_search\", \"linear_convergence\", \"linear_convergence\", \"linear_convergence\", \"linear_convergence\", \"linear_measurement\", \"linear_measurement\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstms\", \"lstms\", \"machine_translation\", \"machine_translation\", \"machine_translation\", \"machine_translation\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"market\", \"market\", \"market\", \"market\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"markov_chain_monte_carlo\", \"markov_chain_monte_carlo\", \"martinsson\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"mcmc\", \"mcmc\", \"mcmc\", \"mcmc\", \"mcsherry\", \"mean_field\", \"mean_field\", \"mean_field\", \"mean_field\", \"metropolis_hastings\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"multi_armed\", \"multi_armed\", \"multi_armed\", \"multi_armed_bandit_problem\", \"multi_label\", \"multi_label\", \"multi_label\", \"multi_label\", \"multiarmed\", \"multiarmed_bandit\", \"natural_image\", \"natural_image\", \"natural_image\", \"natural_image\", \"need_least\", \"netrapalli\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nonstochastic\", \"nuclear_norm\", \"nuclear_norm\", \"nuclear_norm\", \"nuclear_norm\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_recognition\", \"online_learning\", \"online_learning\", \"online_learning\", \"online_learning\", \"optimal_control\", \"optimal_control\", \"optimal_control\", \"optimal_control\", \"optimal_solution\", \"optimal_solution\", \"optimal_solution\", \"optimal_solution\", \"parent\", \"parent\", \"parent\", \"parent\", \"parsing\", \"particle\", \"particle\", \"particle\", \"particle\", \"patch\", \"patch\", \"peter_auer\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"player\", \"player\", \"player\", \"player\", \"point_process\", \"point_process\", \"point_process\", \"point_process\", \"poisson\", \"poisson\", \"poisson\", \"poisson\", \"poisson_process\", \"poisson_process\", \"poisson_process\", \"policy\", \"policy\", \"policy\", \"policy\", \"polynomial_time\", \"polynomial_time\", \"polynomial_time\", \"polynomial_time\", \"pooling_layer\", \"population\", \"population\", \"population\", \"population\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_inference\", \"posterior_mean\", \"posterior_mean\", \"posterior_mean\", \"posterior_mean\", \"posterior_predictive\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"primal\", \"primal\", \"primal\", \"primal\", \"primal_dual\", \"primal_dual\", \"primal_dual\", \"primal_dual\", \"principal_component\", \"principal_component\", \"principal_component\", \"principal_component\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"private\", \"private\", \"private\", \"private\", \"probability_least\", \"probability_least\", \"probability_least\", \"probability_least\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"proposal_distribution\", \"proposal_distribution\", \"proposal_distribution\", \"proposal_distribution\", \"proximal\", \"proximal\", \"proximal\", \"proximal\", \"query\", \"query\", \"query\", \"query\", \"random_walk\", \"random_walk\", \"random_walk\", \"random_walk\", \"rank_approximation\", \"rank_approximation\", \"rank_approximation\", \"rank_approximation\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"ranking\", \"ranking\", \"ranking\", \"ranking\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent_connection\", \"recurrent_convolutional\", \"recurrent_network\", \"recurrent_network\", \"recurrent_network\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regret_minimization\", \"regret_regret\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"relative_error\", \"relative_error\", \"relative_error\", \"relative_error\", \"relu\", \"restricted_strong\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward_function\", \"reward_function\", \"reward_function\", \"reward_function\", \"richta_taka\", \"rnns\", \"rnns\", \"round\", \"round\", \"round\", \"round\", \"running_time\", \"running_time\", \"running_time\", \"running_time\", \"sample_complexity\", \"sample_complexity\", \"sample_complexity\", \"sample_complexity\", \"sample_size\", \"sample_size\", \"sample_size\", \"sample_size\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"sanghavi\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"semantic_segmentation\", \"semantic_segmentation\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"semidefinite_programming\", \"semidefinite_programming\", \"semidefinite_programming\", \"semidefinite_programming\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sequence_sequence\", \"sequence_sequence\", \"sequence_sequence\", \"sequence_sequence\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_vector\", \"singular_vector\", \"singular_vector\", \"singular_vector\", \"sketching\", \"sketching\", \"sketching\", \"softmax_layer\", \"sparse_recovery\", \"sparse_recovery\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spectral_norm\", \"spectral_norm\", \"spectral_norm\", \"spectral_norm\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"squared_exponential\", \"stack\", \"stack\", \"stack\", \"stack\", \"state_space\", \"state_space\", \"state_space\", \"state_space\", \"stationary_distribution\", \"stationary_distribution\", \"stationary_distribution\", \"stationary_distribution\", \"statistical_guarantee\", \"statistical_guarantee\", \"statistical_guarantee\", \"step_size\", \"step_size\", \"step_size\", \"step_size\", \"stochastic_bandit\", \"stochastic_nonstochastic\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_variational\", \"stochastic_variational\", \"stochastic_variational\", \"stochastic_variational\", \"strong_convexity\", \"strong_convexity\", \"strong_convexity\", \"strongly_convex\", \"strongly_convex\", \"strongly_convex\", \"strongly_convex\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular_function\", \"submodular_function\", \"submodular_function\", \"submodular_function\", \"submodular_maximization\", \"submodular_maximization\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"sujay\", \"sujay_sanghavi\", \"sutskever\", \"sutskever\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor_decomposition\", \"tensor_decomposition\", \"tensor_decomposition\", \"tensor_decomposition\", \"texture\", \"texture\", \"texture\", \"texture\", \"time_series\", \"time_series\", \"time_series\", \"time_series\", \"time_step\", \"time_step\", \"time_step\", \"time_step\", \"titsias\", \"topic_model\", \"topic_model\", \"topic_model\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trial\", \"trial\", \"trial\", \"trial\", \"true_posterior\", \"true_posterior\", \"true_posterior\", \"true_posterior\", \"unlabeled_data\", \"unlabeled_data\", \"unlabeled_data\", \"unlabeled_data\", \"upper_confidence\", \"upper_confidence\", \"variational_distribution\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_objective\", \"variational_parameter\", \"variational_posterior\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"very_deep\", \"visual_recognition\", \"wake\", \"wake\", \"weakly_supervised\", \"weighted_graph\", \"weighted_graph\", \"welfare\", \"welfare\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el354845377146081123936335\", ldavis_el354845377146081123936335_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el354845377146081123936335\", ldavis_el354845377146081123936335_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el354845377146081123936335\", ldavis_el354845377146081123936335_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.081555  0.020833       1        1  28.901733\n",
       "1     -0.023986 -0.136990       2        1  25.234737\n",
       "3      0.124469  0.052723       3        1  23.496025\n",
       "2     -0.182038  0.063433       4        1  22.367505, topic_info=                  Term         Freq        Total Category  logprob  loglift\n",
       "609             regret  1162.000000  1162.000000  Default  30.0000  30.0000\n",
       "3230  gaussian_process   904.000000   904.000000  Default  29.0000  29.0000\n",
       "3048  convergence_rate   927.000000   927.000000  Default  28.0000  28.0000\n",
       "2180     convolutional   661.000000   661.000000  Default  27.0000  27.0000\n",
       "3192            bandit   669.000000   669.000000  Default  26.0000  26.0000\n",
       "...                ...          ...          ...      ...      ...      ...\n",
       "1406          proposal   356.855427   579.067008   Topic4  -5.6213   1.0135\n",
       "134       ground_truth   407.639159   797.063976   Topic4  -5.4883   0.8270\n",
       "473          embedding   341.428976   619.398785   Topic4  -5.6655   0.9020\n",
       "1062            filter   248.860122   376.963164   Topic4  -5.9818   1.0823\n",
       "3353  generative_model   293.792600   795.344753   Topic4  -5.8158   0.5017\n",
       "\n",
       "[294 rows x 6 columns], token_table=      Topic      Freq                  Term\n",
       "term                                       \n",
       "4738      3  0.986850  accelerated_proximal\n",
       "1228      2  0.972057            acceptance\n",
       "3185      1  0.829671       active_learning\n",
       "3185      2  0.055311       active_learning\n",
       "3185      3  0.094179       active_learning\n",
       "...     ...       ...                   ...\n",
       "5637      4  0.986789     weakly_supervised\n",
       "2132      1  0.982054        weighted_graph\n",
       "2132      2  0.010912        weighted_graph\n",
       "3015      1  0.012293               welfare\n",
       "3015      3  0.983446               welfare\n",
       "\n",
       "[794 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 4, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "gensimvis.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa6b35ff-22bf-44a7-ba48-2c7a368407fe",
    "_uuid": "864ddc392f72ba631bf372d038385d72301816ec",
    "id": "_cmy3kuwePQM"
   },
   "source": [
    "** O que vemos aqui? **\n",
    "\n",
    "** O painel esquerdo **, rotulado Mapa de distância intertópica, os círculos representam diferentes tópicos e a distância entre eles. Tópicos semelhantes aparecem mais próximos e tópicos diferentes mais distantes.\n",
    "O tamanho relativo do círculo de um tópico no gráfico corresponde à frequência relativa do tópico no corpus.\n",
    "Um tópico individual pode ser selecionado para um exame mais detalhado clicando em seu círculo ou inserindo seu número na caixa \"tópico selecionado\" no canto superior esquerdo.\n",
    " \n",
    "** O painel direito ** inclui o gráfico de barras dos 30 principais termos. Quando nenhum tópico é selecionado no gráfico à esquerda, o gráfico de barras mostra os 30 termos mais \"salientes\" no corpus. A saliência de um termo é uma medida de quão frequente o termo é no corpus e quão \"distinto\" ele é na distinção entre diferentes tópicos.\n",
    "Selecionar cada tópico à direita modifica o gráfico de barras para mostrar os termos \"relevantes\" para o tópico selecionado.\n",
    "A relevância é definida como no rodapé 2 e pode ser ajustada pelo parâmetro $ \\ lambda $, menor $ \\ lambda $ dá maior peso à distinção do termo, enquanto $ \\ lambda $ s maior corresponde à probabilidade da ocorrência do termo por tópicos.\n",
    "\n",
    "Portanto, para ter uma noção melhor dos termos por tópico, usaremos $ \\ lambda $ = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "66d42d65-8258-40bf-9fb0-d304f4ed54ea",
    "_uuid": "132463131ee73972307d5a3560da8db816f519e2",
    "id": "7oK7drBkePQN"
   },
   "source": [
    "** Como avaliar nosso modelo? **\n",
    "Então, novamente, uma vez que não há base para aqui, temos que ser criativos na definição de maneiras de avaliar. Eu faço isso em duas etapas:\n",
    "\n",
    "1. divida cada documento em duas partes e veja se os tópicos atribuídos a eles são semelhantes. => quanto mais semelhante, melhor\n",
    "2. comparar documentos escolhidos aleatoriamente entre si. => quanto menos semelhante melhor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b757e081-e199-4f92-8f86-22bd82050dc6",
    "_uuid": "60006b777f680005368652ec6a395d873b80b246",
    "id": "a8imGhSQePQR"
   },
   "source": [
    "transformando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc62349-d01d-4fe7-8daf-7996155e8c70",
    "_uuid": "33ecddaa5755866ad6e9f8f7c5072859d09c27b4",
    "id": "aUUcA-29ePQb"
   },
   "source": [
    "\n",
    "De cima, é possível inspecionar cada tópico e atribuir um rótulo interpretável por humanos a ele. Aqui, eu os rotulei da seguinte maneira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633379058963,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "55Yt0CX0F-Pr"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def get_doc_topic_dist(model, corpus, kwords=False):\n",
    "    \n",
    "    '''\n",
    "   A transformação LDA, para cada doc retorna apenas tópicos com peso diferente de zero\n",
    "     Esta função faz uma transformação de matriz de documentos no espaço do tópico.\n",
    "    '''\n",
    "    top_dist =[]\n",
    "    keys = []\n",
    "\n",
    "    for d in corpus:\n",
    "        tmp = {i:0 for i in range(num_topics)}\n",
    "        tmp.update(dict(model[d]))\n",
    "        vals = list(OrderedDict(tmp).values())\n",
    "        top_dist += [array(vals)]\n",
    "        if kwords:\n",
    "            keys += [array(vals).argmax()]\n",
    "\n",
    "    return array(top_dist), keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633379058963,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "jH34TtCCvxCh"
   },
   "outputs": [],
   "source": [
    "def explore_topic(lda_model, topic_number, topn, output=True):\n",
    "    \"\"\"\n",
    "    accept a ldamodel, atopic number and topn vocabs of interest\n",
    "    prints a formatted list of the topn terms\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
    "        terms += [term]\n",
    "        if output:\n",
    "            print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))\n",
    "    \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1633379058964,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "bGgZ45_8vz3R",
    "outputId": "a6a87a53-444b-47bc-aa30-38fbf1b2547a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "Topic 0 |---------------------\n",
      "\n",
      "data_set             0.005\n",
      "convergence_rate     0.004\n",
      "line_search          0.004\n",
      "active_learning      0.004\n",
      "strongly_convex      0.004\n",
      "random_walk          0.004\n",
      "query                0.004\n",
      "empirical_risk       0.003\n",
      "primal_dual          0.003\n",
      "first_order          0.003\n",
      "Topic 1 |---------------------\n",
      "\n",
      "gaussian_process     0.008\n",
      "variational_inference 0.006\n",
      "tensor               0.006\n",
      "matrix_completion    0.004\n",
      "gibbs_sampling       0.004\n",
      "posterior_distribution 0.004\n",
      "gibbs                0.004\n",
      "topic_model          0.004\n",
      "sampler              0.004\n",
      "markov_chain         0.003\n",
      "Topic 2 |---------------------\n",
      "\n",
      "sample_complexity    0.005\n",
      "submodular           0.005\n",
      "vertex               0.005\n",
      "step_size            0.004\n",
      "convergence_rate     0.004\n",
      "probability_least    0.004\n",
      "running_time         0.004\n",
      "graphical_model      0.004\n",
      "sample_size          0.004\n",
      "markov_chain         0.004\n",
      "Topic 3 |---------------------\n",
      "\n",
      "regret               0.008\n",
      "convolutional        0.005\n",
      "bandit               0.005\n",
      "deep_learning        0.004\n",
      "fully_connected      0.004\n",
      "recurrent            0.004\n",
      "recurrent_neural     0.004\n",
      "generative_model     0.004\n",
      "lstm                 0.004\n",
      "regret_bound         0.004\n"
     ]
    }
   ],
   "source": [
    "topic_summaries = []\n",
    "print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "for i in range(num_topics):\n",
    "    print('Topic '+str(i)+' |---------------------\\n')\n",
    "    tmp = explore_topic(model,topic_number=i, topn=10, output=True )\n",
    "#     print tmp[:5]\n",
    "    topic_summaries += [tmp[:5]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633379058965,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Z22RYNne-Y1r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LDAartigos_(2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
