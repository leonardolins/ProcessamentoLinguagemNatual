{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQlCey2SjAKR"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td><center style=\"font-size:500%;\">Representação Distribuida de Palavras (Parte 1)</center></td>\n",
    "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
    "  </tr>    \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:03:15.567209Z",
     "start_time": "2022-01-19T15:03:11.215974Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-NwNYVhx8jm",
    "outputId": "7a15b799-efcb-45dd-fe35-f171fc0af51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\r\n",
      "Version: 3.6.0\r\n",
      "Summary: Python framework for fast Vector Space Modelling\r\n",
      "Home-page: http://radimrehurek.com/gensim\r\n",
      "Author: Radim Rehurek\r\n",
      "Author-email: me@radimrehurek.com\r\n",
      "License: LGPLv2.1\r\n",
      "Location: /opt/anaconda3/lib/python3.8/site-packages\r\n",
      "Requires: smart-open, scipy, numpy, six\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:27.866725Z",
     "start_time": "2022-01-19T15:04:42.998216Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4px4rMC57O4R",
    "outputId": "db309310-b9ef-4442-ff6a-18196ed60f08"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#carrega um modelo pré-treinado (gloVe word vectors)\n",
    "word_vectors = api.load('glove-wiki-gigaword-50')\n",
    "\n",
    "# função de word -> vec\n",
    "word2vec = lambda w: word_vectors.word_vec(w.lower())\n",
    "#word2vec = lambda w: word_vectors.get_vector(w.lower()) #nova versao fdo gensim 4.1.0\n",
    "\n",
    "#função de similaridade\n",
    "similarity = lambda x,y:cosine_similarity(x[np.newaxis,:],y[np.newaxis,:]).squeeze()\n",
    "#[np.newaxis:1] converte um array 1D para 2D. No caso [50,] para [1,50]. A funcão cosine_similaruty precisa de um\n",
    "#vetor com n_samples, n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:48.982543Z",
     "start_time": "2022-01-19T15:05:48.974486Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEHKU6DbALbZ",
    "outputId": "c90531e1-be94-4506-e1c1-8e531a85a78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( blue , yellow ): 0.8321\n"
     ]
    }
   ],
   "source": [
    "#word_a, word_b = \"king\", \"queen\"\n",
    "word_a, word_b = \"blue\", \"yellow\"\n",
    "\n",
    "vec_a = word2vec(word_a) #transforma em word2vec\n",
    "vec_b = word2vec(word_b) #transforma em word2vec\n",
    "\n",
    "#calcula similaridade entre vec_a e vec_b\n",
    "result = similarity(vec_a, vec_b).squeeze()\n",
    "print(\"cosine_similarity( {} , {} ): {:.4f}\".format(word_a,word_b,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:55.383720Z",
     "start_time": "2022-01-19T15:05:55.363646Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5sfCGcLDGvq",
    "outputId": "69f2a11c-356b-4b22-d85b-460cee9b50d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( france - paris , italy - rome ): 0.6751\n",
      "cosine_similarity( france - paris , rome - italy ): -0.6751\n"
     ]
    }
   ],
   "source": [
    "pos_a, neg_a = \"france\" , \"paris\"\n",
    "pos_a_v = word2vec(pos_a)\n",
    "neg_a_v = word2vec(neg_a)\n",
    "\n",
    "pos_b, neg_b = \"italy\", \"rome\"\n",
    "pos_b_v = word2vec(pos_b)\n",
    "neg_b_v = word2vec(neg_b)\n",
    "\n",
    "#Quão similar são as palavras:\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, pos_b_v - neg_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, pos_b, neg_b, result))\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, neg_b_v - pos_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, neg_b, pos_b, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:59.452305Z",
     "start_time": "2022-01-19T15:05:59.444164Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrVzfwWXOWWR",
    "outputId": "a0643944-4ad8-4317-e0b6-60ada041919c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.43528992 -0.89909     0.546175    0.14104998  0.99908     0.13400999\n",
      "  0.38700008 -0.64735    -0.637116    0.59869    -0.31992    -1.67881\n",
      "  1.72769    -0.55635     0.077877   -0.58527994 -0.579828   -0.151812\n",
      "  0.963201   -0.54823995 -0.87078    -0.557199    0.06807998  0.90702\n",
      "  0.05069999  1.41682     0.40825     0.11616999 -0.799819   -0.278025\n",
      " -0.7675998   1.1688      0.08175199 -0.6893699  -0.345674   -0.56614\n",
      " -0.76390004 -0.12868002  0.512343    0.13447998 -0.93983996  0.4739176\n",
      " -0.76528     0.88283    -1.02021    -0.50976    -0.07191998 -0.13142\n",
      "  1.35542     0.19582999]\n"
     ]
    }
   ],
   "source": [
    "#g = word2vec('women')\n",
    "#g = word2vec('woman') - word2vec('man')\n",
    "g = word2vec('hispanic') - word2vec('american')\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:01.405343Z",
     "start_time": "2022-01-19T15:06:01.381501Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjiXp7qKCZX1",
    "outputId": "da3ddbce-489c-4a25-9223-edef7d93e6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de nomes e sua similaridade com o vetor g:\n",
      "john:-0.3658096194267273\n",
      "marie:-0.17237810790538788\n",
      "sophie:-0.2450234442949295\n",
      "ronaldo:-0.014981400221586227\n",
      "priya:0.10761348903179169\n",
      "rahul:-0.10907028615474701\n",
      "danielle:-0.13969191908836365\n",
      "reza:-0.207201287150383\n",
      "katy:-0.05387929826974869\n",
      "yasmin:0.07244789600372314\n"
     ]
    }
   ],
   "source": [
    "#Nomes masculinos são negativos\n",
    "print ('Lista de nomes e sua similaridade com o vetor g:')\n",
    "\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "for word in name_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:03.668673Z",
     "start_time": "2022-01-19T15:06:03.644229Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRNP3_VbTpNn",
    "outputId": "dd4bb229-7eb8-4c11-839e-6207a4b8fe4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outras palavras e suas similaridades:\n",
      "lipstick:0.028396347537636757\n",
      "guns:-0.32811033725738525\n",
      "science:-0.2437894642353058\n",
      "arts:-0.16481715440750122\n",
      "literature:-0.15814538300037384\n",
      "warrior:-0.3153199851512909\n",
      "doctor:-0.2643163204193115\n",
      "tree:-0.013971754349768162\n",
      "receptionist:0.08079687505960464\n",
      "technology:-0.2412266731262207\n",
      "fashion:-0.14138080179691315\n",
      "teacher:-0.1181369498372078\n",
      "engineer:-0.40797320008277893\n",
      "pilot:-0.398493230342865\n",
      "computer:-0.11333662271499634\n",
      "singer:-0.20428600907325745\n"
     ]
    }
   ],
   "source": [
    "print('Outras palavras e suas similaridades:')\n",
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for word in word_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:29.237554Z",
     "start_time": "2022-01-19T15:06:29.230246Z"
    },
    "id": "smFPk51uu_w7"
   },
   "outputs": [],
   "source": [
    "def complete_analogy(pos_a, neg_a, pos_b):\n",
    "    \n",
    "    pos_a_v, neg_a_v, pos_b_v = word2vec(pos_a), word2vec(neg_a), word2vec(pos_b)\n",
    "    #calculo a diferença\n",
    "    d = pos_a_v - neg_a_v\n",
    "    #vou atualizando o valor no for\n",
    "    max_cosine_sim = -1            \n",
    "    best_word = None                   \n",
    "\n",
    "    for neg_b in word_vectors.vocab:   \n",
    "    #for neg_b in word_vectors.key_to_index: #nova versao do gensim\n",
    "        \n",
    "        if neg_b in [pos_a, neg_a, pos_b] :\n",
    "            continue\n",
    "            \n",
    "        neg_b_v = word2vec(neg_b)\n",
    "        #busca pos v com neg B\n",
    "        cosine_sim = similarity(d , pos_b_v - neg_b_v)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = neg_b\n",
    "            \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZZP5jH9ABg6"
   },
   "source": [
    "# as duas palavras fazem a analogia como argentina "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:19:40.244463Z",
     "start_time": "2022-01-19T15:06:30.771577Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwt27kGovEEZ",
    "outputId": "e6b443ad-1705-4712-d4fd-81d86b9299ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: argentina -> argentine\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "analogies_to_try = [('italy', 'italian', 'argentina'), \n",
    "                 ('india', 'delhi', 'japan'), \n",
    "                 ('man', 'woman', 'boy'), \n",
    "                 ('small', 'smaller', 'large')]\n",
    "\n",
    "# dadas 3 palavras, encontre a próxima palavra\n",
    "for analogy in analogies_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format(*analogy, complete_analogy(*analogy))) #* serve para unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word_Representation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
