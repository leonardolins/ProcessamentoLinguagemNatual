{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQlCey2SjAKR"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td><center style=\"font-size:500%;\">Representação Distribuida de Palavras (Parte 1)</center></td>\n",
    "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
    "  </tr>    \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:03:15.567209Z",
     "start_time": "2022-01-19T15:03:11.215974Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-NwNYVhx8jm",
    "outputId": "7a15b799-efcb-45dd-fe35-f171fc0af51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\r\n",
      "Version: 3.6.0\r\n",
      "Summary: Python framework for fast Vector Space Modelling\r\n",
      "Home-page: http://radimrehurek.com/gensim\r\n",
      "Author: Radim Rehurek\r\n",
      "Author-email: me@radimrehurek.com\r\n",
      "License: LGPLv2.1\r\n",
      "Location: /opt/anaconda3/lib/python3.8/site-packages\r\n",
      "Requires: smart-open, scipy, numpy, six\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:27.866725Z",
     "start_time": "2022-01-19T15:04:42.998216Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4px4rMC57O4R",
    "outputId": "db309310-b9ef-4442-ff6a-18196ed60f08"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#carrega um modelo pré-treinado (gloVe word vectors)\n",
    "word_vectors = api.load('glove-wiki-gigaword-50')\n",
    "\n",
    "# função de word -> vec\n",
    "word2vec = lambda w: word_vectors.word_vec(w.lower())\n",
    "#word2vec = lambda w: word_vectors.get_vector(w.lower()) #nova versao fdo gensim 4.1.0\n",
    "\n",
    "#função de similaridade\n",
    "similarity = lambda x,y:cosine_similarity(x[np.newaxis,:],y[np.newaxis,:]).squeeze()\n",
    "#[np.newaxis:1] converte um array 1D para 2D. No caso [50,] para [1,50]. A funcão cosine_similaruty precisa de um\n",
    "#vetor com n_samples, n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:48.982543Z",
     "start_time": "2022-01-19T15:05:48.974486Z"
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQlCey2SjAKR"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "  <tr>\n",
        "    <td><center style=\"font-size:500%;\">Representação Distribuida de Palavras (Parte 1)</center></td>\n",
        "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
        "  </tr>    \n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T15:48:01.521028Z",
          "start_time": "2022-01-16T15:47:56.965148Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-NwNYVhx8jm",
        "outputId": "7436b337-a785-414a-fb64-82e1ffd79761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gensim\n",
            "Version: 3.6.0\n",
            "Summary: Python framework for fast Vector Space Modelling\n",
            "Home-page: http://radimrehurek.com/gensim\n",
            "Author: Radim Rehurek\n",
            "Author-email: me@radimrehurek.com\n",
            "License: LGPLv2.1\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: smart-open, numpy, six, scipy\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show gensim"
      ]
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T15:49:01.719241Z",
          "start_time": "2022-01-16T15:48:06.319906Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4px4rMC57O4R",
        "outputId": "06530452-68ab-4690-ccdb-ca240c1cd17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#carrega um modelo pré-treinado (gloVe word vectors)\n",
        "word_vectors = api.load('glove-wiki-gigaword-50')\n",
        "\n",
        "# função de word -> vec\n",
        "#word2vec = lambda w: word_vectors.word_vec(w.lower())\n",
        "word2vec = lambda w: word_vectors.get_vector(w.lower())\n",
        "\n",
        "#função de similaridade\n",
        "similarity = lambda x,y:cosine_similarity(x[np.newaxis,:],y[np.newaxis,:]).squeeze()\n",
        "#[np.newaxis:1] converte um array 1D para 2D. No caso [50,] para [1,50]. A funcão cosine_similaruty precisa de um\n",
        "#vetor com n_samples, n_features."
      ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( blue , yellow ): 0.8321\n"
     ]
    }
   ],
   "source": [
    "#word_a, word_b = \"king\", \"queen\"\n",
    "word_a, word_b = \"blue\", \"yellow\"\n",
    "\n",
    "vec_a = word2vec(word_a) #transforma em word2vec\n",
    "vec_b = word2vec(word_b) #transforma em word2vec\n",
    "\n",
    "#calcula similaridade entre vec_a e vec_b\n",
    "result = similarity(vec_a, vec_b).squeeze()\n",
    "print(\"cosine_similarity( {} , {} ): {:.4f}\".format(word_a,word_b,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:55.383720Z",
     "start_time": "2022-01-19T15:05:55.363646Z"
=======
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T16:25:37.233994Z",
          "start_time": "2022-01-16T16:25:37.226873Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEHKU6DbALbZ",
        "outputId": "805a95f3-4f22-4cb5-ed51-44c02cc76d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine_similarity( blue , yellow ): 0.8321\n"
          ]
        }
      ],
      "source": [
        "#word_a, word_b = \"king\", \"queen\"\n",
        "word_a, word_b = \"blue\", \"yellow\"\n",
        "\n",
        "vec_a = word2vec(word_a) #transforma em word2vec\n",
        "vec_b = word2vec(word_b) #transforma em word2vec\n",
        "\n",
        "#calcula similaridade entre vec_a e vec_b\n",
        "result = similarity(vec_a, vec_b).squeeze()\n",
        "print(\"cosine_similarity( {} , {} ): {:.4f}\".format(word_a,word_b,result))"
      ]
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T16:28:56.253789Z",
          "start_time": "2022-01-16T16:28:56.242683Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5sfCGcLDGvq",
        "outputId": "3929f943-3aee-4d12-e0c7-453ac142126e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine_similarity( france - paris , italy - rome ): 0.6751\n",
            "cosine_similarity( france - paris , rome - italy ): -0.6751\n"
          ]
        }
      ],
      "source": [
        "pos_a, neg_a = \"france\" , \"paris\"\n",
        "pos_a_v = word2vec(pos_a)\n",
        "neg_a_v = word2vec(neg_a)\n",
        "\n",
        "pos_b, neg_b = \"italy\", \"rome\"\n",
        "pos_b_v = word2vec(pos_b)\n",
        "neg_b_v = word2vec(neg_b)\n",
        "\n",
        "#Quão similar são as palavras:\n",
        "\n",
        "result = similarity(pos_a_v - neg_a_v, pos_b_v - neg_b_v)\n",
        "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, pos_b, neg_b, result))\n",
        "\n",
        "result = similarity(pos_a_v - neg_a_v, neg_b_v - pos_b_v)\n",
        "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, neg_b, pos_b, result))"
      ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( france - paris , italy - rome ): 0.6751\n",
      "cosine_similarity( france - paris , rome - italy ): -0.6751\n"
     ]
    }
   ],
   "source": [
    "pos_a, neg_a = \"france\" , \"paris\"\n",
    "pos_a_v = word2vec(pos_a)\n",
    "neg_a_v = word2vec(neg_a)\n",
    "\n",
    "pos_b, neg_b = \"italy\", \"rome\"\n",
    "pos_b_v = word2vec(pos_b)\n",
    "neg_b_v = word2vec(neg_b)\n",
    "\n",
    "#Quão similar são as palavras:\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, pos_b_v - neg_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, pos_b, neg_b, result))\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, neg_b_v - pos_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, neg_b, pos_b, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:05:59.452305Z",
     "start_time": "2022-01-19T15:05:59.444164Z"
=======
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T17:38:23.170887Z",
          "start_time": "2022-01-16T17:38:23.164024Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrVzfwWXOWWR",
        "outputId": "5353522d-8d6d-47fa-d19e-2b7e945c7860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.43528992 -0.89909     0.546175    0.14104998  0.99908     0.13400999\n",
            "  0.38700008 -0.64735    -0.637116    0.59869    -0.31992    -1.67881\n",
            "  1.72769    -0.55635     0.077877   -0.58527994 -0.579828   -0.151812\n",
            "  0.963201   -0.54823995 -0.87078    -0.557199    0.06807998  0.90702\n",
            "  0.05069999  1.41682     0.40825     0.11616999 -0.799819   -0.278025\n",
            " -0.7675998   1.1688      0.08175199 -0.6893699  -0.345674   -0.56614\n",
            " -0.76390004 -0.12868002  0.512343    0.13447998 -0.93983996  0.4739176\n",
            " -0.76528     0.88283    -1.02021    -0.50976    -0.07191998 -0.13142\n",
            "  1.35542     0.19582999]\n"
          ]
        }
      ],
      "source": [
        "#g = word2vec('women')\n",
        "#g = word2vec('woman') - word2vec('man')\n",
        "g = word2vec('hispanic') - word2vec('american')\n",
        "\n",
        "print(g)"
      ]
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T17:38:26.661576Z",
          "start_time": "2022-01-16T17:38:26.641546Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjiXp7qKCZX1",
        "outputId": "6a8905a8-9a8f-489f-d4b4-af72ca6e3ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de nomes e sua similaridade com o vetor g:\n",
            "john:-0.3658096194267273\n",
            "marie:-0.17237810790538788\n",
            "sophie:-0.2450234442949295\n",
            "ronaldo:-0.014981400221586227\n",
            "priya:0.10761348903179169\n",
            "rahul:-0.10907028615474701\n",
            "danielle:-0.13969191908836365\n",
            "reza:-0.207201287150383\n",
            "katy:-0.05387929826974869\n",
            "yasmin:0.07244789600372314\n"
          ]
        }
      ],
      "source": [
        "#Nomes masculinos são negativos\n",
        "print ('Lista de nomes e sua similaridade com o vetor g:')\n",
        "\n",
        "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
        "\n",
        "for word in name_list:\n",
        "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
      ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.43528992 -0.89909     0.546175    0.14104998  0.99908     0.13400999\n",
      "  0.38700008 -0.64735    -0.637116    0.59869    -0.31992    -1.67881\n",
      "  1.72769    -0.55635     0.077877   -0.58527994 -0.579828   -0.151812\n",
      "  0.963201   -0.54823995 -0.87078    -0.557199    0.06807998  0.90702\n",
      "  0.05069999  1.41682     0.40825     0.11616999 -0.799819   -0.278025\n",
      " -0.7675998   1.1688      0.08175199 -0.6893699  -0.345674   -0.56614\n",
      " -0.76390004 -0.12868002  0.512343    0.13447998 -0.93983996  0.4739176\n",
      " -0.76528     0.88283    -1.02021    -0.50976    -0.07191998 -0.13142\n",
      "  1.35542     0.19582999]\n"
     ]
    }
   ],
   "source": [
    "#g = word2vec('women')\n",
    "#g = word2vec('woman') - word2vec('man')\n",
    "g = word2vec('hispanic') - word2vec('american')\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:01.405343Z",
     "start_time": "2022-01-19T15:06:01.381501Z"
=======
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T17:38:29.674331Z",
          "start_time": "2022-01-16T17:38:29.644905Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRNP3_VbTpNn",
        "outputId": "63b9785e-4cfb-4b68-e28d-cf5659426015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outras palavras e suas similaridades:\n",
            "lipstick:0.028396347537636757\n",
            "guns:-0.32811033725738525\n",
            "science:-0.2437894642353058\n",
            "arts:-0.16481715440750122\n",
            "literature:-0.15814538300037384\n",
            "warrior:-0.3153199851512909\n",
            "doctor:-0.2643163204193115\n",
            "tree:-0.013971754349768162\n",
            "receptionist:0.08079687505960464\n",
            "technology:-0.2412266731262207\n",
            "fashion:-0.14138080179691315\n",
            "teacher:-0.1181369498372078\n",
            "engineer:-0.40797320008277893\n",
            "pilot:-0.398493230342865\n",
            "computer:-0.11333662271499634\n",
            "singer:-0.20428600907325745\n"
          ]
        }
      ],
      "source": [
        "print('Outras palavras e suas similaridades:')\n",
        "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
        "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
        "for word in word_list:\n",
        "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
      ]
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T21:06:11.176756Z",
          "start_time": "2022-01-16T21:06:11.153570Z"
        },
        "id": "smFPk51uu_w7"
      },
      "outputs": [],
      "source": [
        "def complete_analogy(pos_a, neg_a, pos_b):\n",
        "    \n",
        "    pos_a_v, neg_a_v, pos_b_v = word2vec(pos_a), word2vec(neg_a), word2vec(pos_b)\n",
        "    #calculo a diferença\n",
        "    d = pos_a_v - neg_a_v\n",
        "    #vou atualizando o valor no for\n",
        "    max_cosine_sim = -1            \n",
        "    best_word = None                   \n",
        "\n",
        "    for neg_b in word_vectors.vocab:  #para rodar no colab \n",
        "    #for neg_b in word_vectors.key_to_index: \n",
        "        \n",
        "        if neg_b in [pos_a, neg_a, pos_b] :\n",
        "            continue\n",
        "            \n",
        "        neg_b_v = word2vec(neg_b)\n",
        "        #busca pos v com neg B\n",
        "        cosine_sim = similarity(d , pos_b_v - neg_b_v)\n",
        "        \n",
        "        if cosine_sim > max_cosine_sim:\n",
        "            max_cosine_sim = cosine_sim\n",
        "            best_word = neg_b\n",
        "            \n",
        "    return best_word"
      ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de nomes e sua similaridade com o vetor g:\n",
      "john:-0.3658096194267273\n",
      "marie:-0.17237810790538788\n",
      "sophie:-0.2450234442949295\n",
      "ronaldo:-0.014981400221586227\n",
      "priya:0.10761348903179169\n",
      "rahul:-0.10907028615474701\n",
      "danielle:-0.13969191908836365\n",
      "reza:-0.207201287150383\n",
      "katy:-0.05387929826974869\n",
      "yasmin:0.07244789600372314\n"
     ]
    }
   ],
   "source": [
    "#Nomes masculinos são negativos\n",
    "print ('Lista de nomes e sua similaridade com o vetor g:')\n",
    "\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "for word in name_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:03.668673Z",
     "start_time": "2022-01-19T15:06:03.644229Z"
=======
      "cell_type": "markdown",
      "metadata": {
        "id": "JZZP5jH9ABg6"
      },
      "source": [
        "# as duas palavras fazem a analogia como argentina "
      ]
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-16T21:19:26.214309Z",
          "start_time": "2022-01-16T21:06:59.160141Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwt27kGovEEZ",
        "outputId": "1dbd76f6-8e7a-4074-83b3-9c4a71a57893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italy -> italian :: argentina -> argentine\n",
            "india -> delhi :: japan -> tokyo\n",
            "man -> woman :: boy -> girl\n",
            "small -> smaller :: large -> larger\n"
          ]
        }
      ],
      "source": [
        "analogies_to_try = [('italy', 'italian', 'argentina'), \n",
        "                 ('india', 'delhi', 'japan'), \n",
        "                 ('man', 'woman', 'boy'), \n",
        "                 ('small', 'smaller', 'large')]\n",
        "\n",
        "# dadas 3 palavras, encontre a próxima palavra\n",
        "for analogy in analogies_to_try:\n",
        "    print ('{} -> {} :: {} -> {}'.format(*analogy, complete_analogy(*analogy))) #* serve para unpacking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogies_to_try = [('brasil', 'coffee', 'portugal')]\n",
        "\n",
        "# dadas 3 palavras, encontre a próxima palavra\n",
        "for analogy in analogies_to_try:\n",
        "    print ('{} -> {} :: {} -> {}'.format(*analogy, complete_analogy(*analogy))) #* serve para unpacking"
      ],
      "metadata": {
        "id": "iZuRswmFDZQk",
        "outputId": "babc0d31-2661-42b9-aede-69e1d0d68d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brasil -> coffee :: portugal -> food\n"
          ]
        }
      ]
    }
<<<<<<< HEAD
   ],
   "source": [
    "print('Outras palavras e suas similaridades:')\n",
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for word in word_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:06:29.237554Z",
     "start_time": "2022-01-19T15:06:29.230246Z"
    },
    "id": "smFPk51uu_w7"
   },
   "outputs": [],
   "source": [
    "def complete_analogy(pos_a, neg_a, pos_b):\n",
    "    \n",
    "    pos_a_v, neg_a_v, pos_b_v = word2vec(pos_a), word2vec(neg_a), word2vec(pos_b)\n",
    "    #calculo a diferença\n",
    "    d = pos_a_v - neg_a_v\n",
    "    #vou atualizando o valor no for\n",
    "    max_cosine_sim = -1            \n",
    "    best_word = None                   \n",
    "\n",
    "    for neg_b in word_vectors.vocab:   \n",
    "    #for neg_b in word_vectors.key_to_index: #nova versao do gensim\n",
    "        \n",
    "        if neg_b in [pos_a, neg_a, pos_b] :\n",
    "            continue\n",
    "            \n",
    "        neg_b_v = word2vec(neg_b)\n",
    "        #busca pos v com neg B\n",
    "        cosine_sim = similarity(d , pos_b_v - neg_b_v)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = neg_b\n",
    "            \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZZP5jH9ABg6"
   },
   "source": [
    "# as duas palavras fazem a analogia como argentina "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-19T15:19:40.244463Z",
     "start_time": "2022-01-19T15:06:30.771577Z"
    },
=======
  ],
  "metadata": {
    "accelerator": "GPU",
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
    "colab": {
      "collapsed_sections": [],
      "name": "Word_Representation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
<<<<<<< HEAD
   ],
   "source": [
    "analogies_to_try = [('italy', 'italian', 'argentina'), \n",
    "                 ('india', 'delhi', 'japan'), \n",
    "                 ('man', 'woman', 'boy'), \n",
    "                 ('small', 'smaller', 'large')]\n",
    "\n",
    "# dadas 3 palavras, encontre a próxima palavra\n",
    "for analogy in analogies_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format(*analogy, complete_analogy(*analogy))) #* serve para unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word_Representation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
=======
>>>>>>> 24a9843a146d5f498a8d862f55684b9bf130cea1
  },
  "nbformat": 4,
  "nbformat_minor": 0
}