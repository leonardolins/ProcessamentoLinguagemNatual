{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQlCey2SjAKR"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td><center style=\"font-size:500%;\">Representação Distribuida de Palavras (Parte 1)</center></td>\n",
    "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
    "  </tr>    \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:46:00.401594Z",
     "start_time": "2022-01-15T04:45:55.610067Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-NwNYVhx8jm",
    "outputId": "7a15b799-efcb-45dd-fe35-f171fc0af51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\r\n",
      "Version: 4.1.2\r\n",
      "Summary: Python framework for fast Vector Space Modelling\r\n",
      "Home-page: http://radimrehurek.com/gensim\r\n",
      "Author: Radim Rehurek\r\n",
      "Author-email: me@radimrehurek.com\r\n",
      "License: LGPL-2.1-only\r\n",
      "Location: /opt/anaconda3/lib/python3.8/site-packages\r\n",
      "Requires: scipy, numpy, smart-open\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:46:54.310911Z",
     "start_time": "2022-01-15T04:46:02.884813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4px4rMC57O4R",
    "outputId": "db309310-b9ef-4442-ff6a-18196ed60f08"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#carrega um modelo pré-treinado (gloVe word vectors)\n",
    "word_vectors = api.load('glove-wiki-gigaword-50')\n",
    "\n",
    "# função de word -> vec\n",
    "#word2vec = lambda w: word_vectors.word_vec(w.lower())\n",
    "word2vec = lambda w: word_vectors.get_vector(w.lower())\n",
    "\n",
    "#função de similaridade\n",
    "similarity = lambda x,y:cosine_similarity(x[np.newaxis,:],y[np.newaxis,:]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:47:01.782279Z",
     "start_time": "2022-01-15T04:47:01.769940Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEHKU6DbALbZ",
    "outputId": "c90531e1-be94-4506-e1c1-8e531a85a78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( father , mother ): 0.8909\n"
     ]
    }
   ],
   "source": [
    "word_a, word_b = \"father\", \"mother\"\n",
    "#word_a, word_b = \"ball\", \"crocodile\"\n",
    "\n",
    "vec_a = word2vec(word_a) #transforma em word2vec\n",
    "vec_b = word2vec(word_b) #transforma em word2vec\n",
    "\n",
    "#calcula similaridade entre vec_a e vec_b\n",
    "result = similarity(vec_a, vec_b).squeeze()\n",
    "print(\"cosine_similarity( {} , {} ): {:.4f}\".format(word_a,word_b,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:47:08.902209Z",
     "start_time": "2022-01-15T04:47:08.880610Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5sfCGcLDGvq",
    "outputId": "69f2a11c-356b-4b22-d85b-460cee9b50d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity( france - paris , italy - rome ): 0.6751\n",
      "cosine_similarity( france - paris , rome - italy ): -0.6751\n"
     ]
    }
   ],
   "source": [
    "pos_a, neg_a = \"france\" , \"paris\"\n",
    "pos_a_v = word2vec(pos_a)\n",
    "neg_a_v = word2vec(neg_a)\n",
    "\n",
    "pos_b, neg_b = \"italy\", \"rome\"\n",
    "pos_b_v = word2vec(pos_b)\n",
    "neg_b_v = word2vec(neg_b)\n",
    "\n",
    "#Quão similar são as palavras:\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, pos_b_v - neg_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, pos_b, neg_b, result))\n",
    "\n",
    "result = similarity(pos_a_v - neg_a_v, neg_b_v - pos_b_v)\n",
    "print(\"cosine_similarity( {} - {} , {} - {} ): {:.4f}\".format(pos_a, neg_a, neg_b, pos_b, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:48:34.237474Z",
     "start_time": "2022-01-15T04:48:34.231047Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrVzfwWXOWWR",
    "outputId": "a0643944-4ad8-4317-e0b6-60ada041919c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59889597  0.256      -0.42293     0.43248898 -1.04424    -0.53832996\n",
      "  0.2845      0.22305998 -0.5121     -0.4179      0.031814    1.34119\n",
      "  0.619771   -1.53227     0.08638     1.28       -0.63721    -0.95950997\n",
      "  0.15139002  0.42474002  1.0251501  -1.40695    -0.147781   -0.59694004\n",
      "  0.02067     0.58640003 -0.36815006 -1.4889     -0.73294     0.62635\n",
      " -0.6197001   0.30341998 -0.47487003  0.45971     0.17943001 -0.14885001\n",
      "  0.21805    -0.243984   -1.0752699   0.73195004  0.487284    0.54300994\n",
      " -0.9561     -0.5096     -0.81159997  1.3143599  -0.43008003 -0.63135\n",
      " -1.1756101  -0.39317003]\n"
     ]
    }
   ],
   "source": [
    "g = word2vec('king') - word2vec('man')\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:48:36.327707Z",
     "start_time": "2022-01-15T04:48:36.309833Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjiXp7qKCZX1",
    "outputId": "da3ddbce-489c-4a25-9223-edef7d93e6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de nomes e sua similaridade com o vetor g:\n",
      "john:0.19528844952583313\n",
      "marie:0.026381026953458786\n",
      "sophie:0.08021946251392365\n",
      "ronaldo:-0.15594151616096497\n",
      "priya:0.07570753246545792\n",
      "rahul:0.09843342006206512\n",
      "danielle:-0.1483866274356842\n",
      "reza:0.11229010671377182\n",
      "katy:-0.0037428135983645916\n",
      "yasmin:0.13542740046977997\n"
     ]
    }
   ],
   "source": [
    "#Nomes masculinos são negativos\n",
    "print ('Lista de nomes e sua similaridade com o vetor g:')\n",
    "\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "for word in name_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:48:50.319192Z",
     "start_time": "2022-01-15T04:48:50.293568Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRNP3_VbTpNn",
    "outputId": "dd4bb229-7eb8-4c11-839e-6207a4b8fe4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outras palavras e suas similaridades:\n",
      "lipstick:-0.29379919171333313\n",
      "guns:-0.2485954612493515\n",
      "science:-0.16056984663009644\n",
      "arts:-0.022254327312111855\n",
      "literature:0.016476832330226898\n",
      "warrior:-0.0667116791009903\n",
      "doctor:-0.22291289269924164\n",
      "tree:-0.16667285561561584\n",
      "receptionist:-0.3380673825740814\n",
      "technology:-0.09191200882196426\n",
      "fashion:-0.24253956973552704\n",
      "teacher:-0.2971269488334656\n",
      "engineer:-0.16246071457862854\n",
      "pilot:-0.24503938853740692\n",
      "computer:-0.17163701355457306\n",
      "singer:-0.12488631159067154\n"
     ]
    }
   ],
   "source": [
    "print('Outras palavras e suas similaridades:')\n",
    "word_list = ['lipstick', 'guns', 'science', 'arts', 'literature', 'warrior','doctor', 'tree', 'receptionist', \n",
    "             'technology',  'fashion', 'teacher', 'engineer', 'pilot', 'computer', 'singer']\n",
    "for word in word_list:\n",
    "    print(\"{}:{}\".format(word, similarity(word2vec(word), g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T04:49:04.612862Z",
     "start_time": "2022-01-15T04:49:04.604934Z"
    },
    "id": "smFPk51uu_w7"
   },
   "outputs": [],
   "source": [
    "def complete_analogy(pos_a, neg_a, pos_b):\n",
    "    \n",
    "    pos_a_v, neg_a_v, pos_b_v = word2vec(pos_a), word2vec(neg_a), word2vec(pos_b)\n",
    "    #calculo a diferença\n",
    "    d = pos_a_v - neg_a_v\n",
    "    #vou atualizando o valor no for\n",
    "    max_cosine_sim = -1            \n",
    "    best_word = None                   \n",
    "\n",
    "    #for neg_b in word_vectors.vocab:   \n",
    "    for neg_b in word_vectors.key_to_index: \n",
    "        \n",
    "        if neg_b in [pos_a, neg_a, pos_b] :\n",
    "            continue\n",
    "            \n",
    "        neg_b_v = word2vec(neg_b)\n",
    "        #busca pos v com neg B\n",
    "        cosine_sim = similarity(d , pos_b_v - neg_b_v)\n",
    "        \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = neg_b\n",
    "            \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZZP5jH9ABg6"
   },
   "source": [
    "# as duas palavras fazem a analogia como argentina "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T05:02:42.853512Z",
     "start_time": "2022-01-15T04:49:05.783242Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwt27kGovEEZ",
    "outputId": "e6b443ad-1705-4712-d4fd-81d86b9299ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: argentina -> argentine\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "analogies_to_try = [('italy', 'italian', 'argentina'), \n",
    "                 ('india', 'delhi', 'japan'), \n",
    "                 ('man', 'woman', 'boy'), \n",
    "                 ('small', 'smaller', 'large')]\n",
    "\n",
    "# dadas 3 palavras, encontre a próxima palavra\n",
    "for analogy in analogies_to_try:\n",
    "    print ('{} -> {} :: {} -> {}'.format( *analogy, complete_analogy(*analogy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQpccKiNeeuW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word_Representation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
