{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kniMXNrNl04"
   },
   "source": [
    "# Projetando sua própria ferramenta de análise de sentimento\n",
    "\n",
    "Embora existam muitas ferramentas que nos darão automaticamente uma sensação de um trecho de texto, aprendemos que nem sempre elas concordam! Vamos projetar o nosso próprio para ver como essas ferramentas funcionam internamente e como podemos testá-las para ver como elas podem funcionar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KxERyGkNl1B"
   },
   "source": [
    "### Trabalho preparatório: baixando os arquivos necessários\n",
    "Antes de começar, precisamos baixar todos os dados que usaremos.\n",
    "* ** sentiment140-subset.csv: ** subconjunto limpo de dados do Sentiment140 - meio milhão de tweets marcados como positivos ou negativos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T20:05:54.186940Z",
     "start_time": "2022-04-10T20:05:48.003381Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1633378942775,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "oCI8mHzXNl1D",
    "outputId": "bc8ad9d2-c318-421b-8b1d-e21396b46719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-10 17:05:48--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/sentiment140-subset.csv.zip\n",
      "Resolvendo nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
      "Conectando-se a nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 17927149 (17M) [application/zip]\n",
      "Salvando em: “data/sentiment140-subset.csv.zip”\n",
      "\n",
      "sentiment140-subset 100%[===================>]  17,10M  4,88MB/s    em 4,1s    \n",
      "\n",
      "2022-04-10 17:05:53 (4,13 MB/s) - “data/sentiment140-subset.csv.zip” salvo [17927149/17927149]\n",
      "\n",
      "Archive:  data/sentiment140-subset.csv.zip\n",
      "  inflating: data/sentiment140-subset.csv  \n"
     ]
    }
   ],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "!mkdir -p data\n",
    "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/sentiment140-subset.csv.zip -P data\n",
    "!unzip -n -d data data/sentiment140-subset.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633378942775,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "7hAiTF4YNl1F"
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbOFauLkNl1F"
   },
   "source": [
    "\n",
    "## Treinamento em tweets\n",
    "\n",
    "Digamos que vamos analisar o sentimento dos tweets. Se tivéssemos uma lista de tweets com pontuação positiva vs. negativa, poderíamos ver quais palavras geralmente estão associadas a pontuações positivas e quais geralmente estão associadas a pontuações negativas.\n",
    "\n",
    "Felizmente, temos ** Sentiment140 ** - http://help.sentiment140.com/for-students - uma lista de 1,6 milhão de tweets junto com uma pontuação para determinar se são negativos ou positivos. Vamos usá-lo para construir nosso próprio algoritmo de aprendizado de máquina para ver separar a positividade da negatividade.\n",
    "\n",
    "### Leia em nossos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1633378943180,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "tU8RgAB-Nl1G",
    "outputId": "d4ae4198-7f6f-4da0-a818-c2470d79c717"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today  coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0                      @kconsidder You never tweet  \n",
       "1         0                 Sick today  coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
       "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
       "4         0  @MrKinetik Not a thing!!!  I don't really have..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/sentiment140-subset.csv\", nrows=30000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_96hyxINl1K"
   },
   "source": [
    "Não é um conjunto de dados muito complicado. `polaridade` é se é positivo ou não,` texto` é o texto do próprio tweet.\n",
    "\n",
    "Quantas linhas nós temos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1633378943181,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "fvBAZmjTNl1L",
    "outputId": "b128c008-6234-412f-cf18-c48469badcec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1ZCrU9aNl1N"
   },
   "source": [
    "Quantos tweets ** positivos ** em comparação com quantos tweets ** negativos **?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1633378943182,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "pHgc-i2JNl1O",
    "outputId": "33406f53-2f44-49fd-f246-2a757be37678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15064\n",
       "0    14936\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pa-99wUXNl1P"
   },
   "source": [
    "## treinando nosso algoritmo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmWHiyxSNl1Q"
   },
   "source": [
    "### Vectorize nossos tweets\n",
    "\n",
    "Crie um `TfidfVectorizer` e use-o para vetorizar nossos tweets. Já que não temos todo o tempo do mundo, provavelmente deveríamos usar `max_features` apenas para pegar uma seleção de termos - que tal 1000 por agora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1633378944337,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Li6kiRKGNl1R"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1633378945005,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "csdGwBIzNl1R",
    "outputId": "469f6c82-0c2f-4a68-a626-8e9b4c6f55ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>2nd</th>\n",
       "      <th>30</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>after</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>again</th>\n",
       "      <th>ago</th>\n",
       "      <th>agree</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ahhh</th>\n",
       "      <th>air</th>\n",
       "      <th>album</th>\n",
       "      <th>all</th>\n",
       "      <th>almost</th>\n",
       "      <th>alone</th>\n",
       "      <th>already</th>\n",
       "      <th>alright</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>annoying</th>\n",
       "      <th>another</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worked</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>worry</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wtf</th>\n",
       "      <th>www</th>\n",
       "      <th>xd</th>\n",
       "      <th>xoxo</th>\n",
       "      <th>xx</th>\n",
       "      <th>xxx</th>\n",
       "      <th>ya</th>\n",
       "      <th>yay</th>\n",
       "      <th>yea</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  100   11   12   15  1st  ...  young  your  yourself  youtube  yum  yup\n",
       "0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "1  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "2  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "3  0.427465  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "4  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHBxeXnyNl1S"
   },
   "source": [
    "### Configurando nossas variáveis\n",
    "\n",
    "Porque queremos nos ajustar com todos os outros programadores, precisamos criar duas variáveis: uma chamada `X` e outra chamada` y`.\n",
    "\n",
    "`X` é todos os nossos ** recursos **, as coisas que usamos para prever o positivo ou o negativo. Essas serão nossas palavras.\n",
    "\n",
    "`y` são todos os nossos ** rótulos **, a avaliação positiva ou negativa. Usaremos a coluna `polaridade` para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633378945006,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "5vXpmVs7Nl1T"
   },
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wCfvwskNl1U"
   },
   "source": [
    "### Escolhendo um algoritmo\n",
    "\n",
    "Que tipo de algoritmo queremos? Quem sabe, não sabemos nada sobre aprendizado de máquina! ** Vamos escolher TODOS ELES. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1633378945286,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "4dCBh5o6Nl1U"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-1NybLnNl1V"
   },
   "source": [
    "### Treinando nossos algoritmos\n",
    "\n",
    "Quando ensinamos nosso algoritmo sobre a aparência de um tweet positivo ou negativo, isso é chamado de ** treinamento **. O treinamento pode levar diferentes períodos de tempo com base no tipo de algoritmo que você está usando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7875,
     "status": "ok",
     "timestamp": 1633378953159,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "6zxCbyEFNl1V",
    "outputId": "9c21fd05-bd94-4b67-adb7-c04fdee22c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.04 s, total: 14.8 s\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a logistic regression\n",
    "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29055,
     "status": "ok",
     "timestamp": 1633378982210,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Ac_ypl9bNl1W",
    "outputId": "62ad93ee-63dd-40b1-dede-d2ccd0886e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 211 ms, total: 27.2 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a random forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=50)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1633378982211,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "bbe3Nl4NNl1W",
    "outputId": "6f6d6d17-a626-4746-9f57-d76257ff36de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 324 ms, sys: 2.07 ms, total: 326 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a linear support vector classifier (LinearSVC)\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1633378982211,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "D5LQcZSvNl1X",
    "outputId": "4f3d95b4-a32e-4ff6-aba7-b7b3461932ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 16 ms, total: 211 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MLYAK1sNl1Y"
   },
   "source": [
    "** Quanto tempo cada um levou para treinar? ** Quão mais rápido alguns foram em comparação com outros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHMzYSqRNl1Y"
   },
   "source": [
    "## Use nossos modelos\n",
    "\n",
    "Agora que treinamos nossos modelos, ** eles podem tentar prever se algum conteúdo é positivo ou negativo **.\n",
    "\n",
    "### Preparando os dados\n",
    "\n",
    "** Adicione mais algumas frases abaixo. ** Elas devem ser uma mistura de positivas e negativas. Eles podem ser enfadonhos, podem ser emocionantes, podem ser curtos, podem ser longos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1633378982212,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "p7dgOQLnNl1Y",
    "outputId": "cb86c514-3283-4de8-99d9-da9331e3cd58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love love love love this kitten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate hate hate hate this keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content\n",
       "0                                         I love love love love this kitten\n",
       "1                                       I hate hate hate hate this keyboard\n",
       "2                                       I'm not sure how I feel about toast\n",
       "3                                  Did you see the baseball game yesterday?\n",
       "4               The package was delivered late and the contents were broken\n",
       "5                          Trashy television shows are some of my favorites\n",
       "6  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\n",
       "7         I find chirping birds irritating, but I know I'm not the only one"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "unknown = pd.DataFrame({'content': [\n",
    "    \"I love love love love this kitten\",\n",
    "    \"I hate hate hate hate this keyboard\",\n",
    "    \"I'm not sure how I feel about toast\",\n",
    "    \"Did you see the baseball game yesterday?\",\n",
    "    \"The package was delivered late and the contents were broken\",\n",
    "    \"Trashy television shows are some of my favorites\",\n",
    "    \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
    "    \"I find chirping birds irritating, but I know I'm not the only one\",\n",
    "]})\n",
    "unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nC2pNWUANl1Z"
   },
   "source": [
    "Primeiro, precisamos ** vetorizar ** nossas sentenças em números, para que o algoritmo possa entendê-las.\n",
    "\n",
    "Nosso algoritmo conhece apenas ** certas palavras. ** Execute `vectorizer.get_feature_names ()` para mostrar a lista de palavras que ele conhece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1633378982212,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "CZNXCJw8Nl1Z",
    "outputId": "4e86f62e-22ca-4ec2-ca2d-9e1b0269761d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '12', '15', '1st', '20', '2day', '2nd', '30', 'able', 'about', 'account', 'actually', 'add', 'after', 'afternoon', 'again', 'ago', 'agree', 'ah', 'ahh', 'ahhh', 'air', 'album', 'all', 'almost', 'alone', 'already', 'alright', 'also', 'although', 'always', 'am', 'amazing', 'amp', 'an', 'and', 'annoying', 'another', 'any', 'anymore', 'anyone', 'anything', 'anyway', 'app', 'apparently', 'apple', 'appreciate', 'are', 'around', 'art', 'as', 'ask', 'asleep', 'ass', 'at', 'ate', 'aw', 'awake', 'awards', 'away', 'awesome', 'aww', 'awww', 'baby', 'back', 'bad', 'band', 'bbq', 'bday', 'be', 'beach', 'beautiful', 'because', 'bed', 'been', 'beer', 'before', 'behind', 'being', 'believe', 'best', 'bet', 'better', 'big', 'bike', 'birthday', 'bit', 'bitch', 'black', 'blip', 'blog', 'blue', 'body', 'boo', 'book', 'books', 'bored', 'boring', 'both', 'bought', 'bout', 'box', 'boy', 'boys', 'break', 'breakfast', 'bring', 'bro', 'broke', 'broken', 'brother', 'brothers', 'btw', 'bus', 'business', 'busy', 'but', 'buy', 'by', 'bye', 'cake', 'call', 'called', 'came', 'can', 'cannot', 'cant', 'car', 'card', 'care', 'case', 'cat', 'catch', 'cause', 'cd', 'chance', 'change', 'channel', 'chat', 'check', 'chicken', 'chocolate', 'church', 'city', 'class', 'clean', 'cleaning', 'close', 'closed', 'club', 'coffee', 'cold', 'college', 'com', 'come', 'comes', 'coming', 'completely', 'computer', 'concert', 'congrats', 'cool', 'cos', 'could', 'couldn', 'country', 'couple', 'course', 'crap', 'crazy', 'cream', 'cry', 'crying', 'cut', 'cute', 'cuz', 'da', 'dad', 'damn', 'dance', 'date', 'daughter', 'david', 'day', 'days', 'ddlovato', 'de', 'dead', 'dear', 'decided', 'definitely', 'did', 'didn', 'didnt', 'die', 'died', 'dinner', 'dm', 'do', 'does', 'doesn', 'doesnt', 'dog', 'doing', 'don', 'done', 'dont', 'down', 'download', 'dream', 'dreams', 'dress', 'drink', 'drinking', 'drive', 'driving', 'drunk', 'dude', 'due', 'during', 'each', 'earlier', 'early', 'easy', 'eat', 'eating', 'either', 'else', 'em', 'email', 'end', 'ended', 'english', 'enjoy', 'enjoyed', 'enjoying', 'enough', 'episode', 'especially', 'even', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'exactly', 'exam', 'exams', 'except', 'excited', 'exciting', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fail', 'fair', 'fall', 'family', 'fan', 'fans', 'far', 'fast', 'favorite', 'fb', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'few', 'ff', 'figure', 'final', 'finally', 'finals', 'find', 'fine', 'fingers', 'finish', 'finished', 'fire', 'first', 'fix', 'flight', 'flu', 'fly', 'fm', 'follow', 'followers', 'followfriday', 'following', 'food', 'for', 'forever', 'forget', 'forgot', 'forward', 'found', 'free', 'friday', 'friend', 'friends', 'from', 'front', 'fuck', 'fucking', 'full', 'fun', 'funny', 'game', 'games', 'garden', 'gave', 'gd', 'get', 'gets', 'getting', 'girl', 'girls', 'give', 'glad', 'go', 'god', 'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodbye', 'goodnight', 'google', 'got', 'gotta', 'graduation', 'great', 'green', 'gt', 'guess', 'guitar', 'guy', 'guys', 'gym', 'ha', 'had', 'haha', 'hahaha', 'hair', 'half', 'hand', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'has', 'hate', 'hates', 'have', 'haven', 'havent', 'having', 'he', 'head', 'headache', 'headed', 'heading', 'hear', 'heard', 'heart', 'hehe', 'hell', 'hello', 'help', 'her', 'here', 'hey', 'hi', 'high', 'him', 'his', 'history', 'hit', 'hmm', 'holiday', 'home', 'homework', 'hope', 'hopefully', 'hoping', 'horrible', 'hot', 'hotel', 'hour', 'hours', 'house', 'how', 'http', 'hubby', 'hug', 'huge', 'hugs', 'hun', 'hungry', 'hurt', 'hurts', 'ice', 'idea', 'idk', 'if', 'ill', 'im', 'in', 'inside', 'instead', 'interesting', 'internet', 'into', 'iphone', 'ipod', 'is', 'isn', 'isnt', 'it', 'its', 'ive', 'jealous', 'job', 'join', 'jonas', 'jonasbrothers', 'july', 'june', 'jus', 'just', 'keep', 'keeps', 'kid', 'kids', 'kill', 'kind', 'kinda', 'knew', 'know', 'knows', 'la', 'lady', 'lakers', 'lame', 'laptop', 'last', 'late', 'later', 'laugh', 'lazy', 'learn', 'learning', 'least', 'leave', 'leaving', 'left', 'less', 'let', 'lets', 'life', 'like', 'liked', 'lil', 'line', 'link', 'list', 'listen', 'listening', 'little', 'live', 'living', 'll', 'lmao', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'lovely', 'loves', 'loving', 'lt', 'luck', 'lucky', 'lunch', 'luv', 'ly', 'ma', 'mac', 'mad', 'made', 'mail', 'major', 'make', 'makes', 'making', 'man', 'many', 'maths', 'matter', 'may', 'maybe', 'mcfly', 'me', 'mean', 'means', 'meant', 'meet', 'meeting', 'message', 'met', 'might', 'miley', 'mileycyrus', 'mind', 'mine', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mom', 'moment', 'monday', 'money', 'month', 'months', 'mood', 'moon', 'more', 'morning', 'most', 'mother', 'mouth', 'move', 'movie', 'movies', 'moving', 'mr', 'mtv', 'much', 'mum', 'music', 'must', 'my', 'myloc', 'myself', 'myspace', 'name', 'nap', 'near', 'need', 'needed', 'needs', 'never', 'new', 'news', 'next', 'nice', 'night', 'nights', 'nite', 'no', 'nope', 'not', 'nothing', 'now', 'number', 'of', 'off', 'office', 'oh', 'ohh', 'ok', 'okay', 'old', 'omg', 'on', 'once', 'one', 'ones', 'online', 'only', 'open', 'or', 'other', 'ouch', 'our', 'out', 'outside', 'over', 'own', 'packing', 'page', 'pain', 'paper', 'parents', 'park', 'part', 'party', 'pass', 'past', 'pay', 'peace', 'people', 'perfect', 'person', 'phone', 'photo', 'photos', 'pic', 'pick', 'pics', 'picture', 'pictures', 'pink', 'pizza', 'place', 'plan', 'plans', 'play', 'played', 'playing', 'please', 'pls', 'plurk', 'plus', 'point', 'pool', 'poor', 'post', 'posted', 'power', 'ppl', 'pretty', 'probably', 'problem', 'profile', 'project', 'proud', 'put', 'quite', 'quot', 'radio', 'rain', 'raining', 'rainy', 'random', 'rather', 're', 'read', 'reading', 'ready', 'real', 'realized', 'really', 'reason', 'red', 'relaxing', 'remember', 'reply', 'rest', 'revision', 'ride', 'right', 'rip', 'road', 'rock', 'room', 'run', 'running', 'sad', 'sadly', 'safe', 'said', 'same', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says', 'scared', 'scary', 'school', 'season', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'send', 'sent', 'seriously', 'set', 'shall', 'shame', 'share', 'she', 'shirt', 'shit', 'shoes', 'shop', 'shopping', 'short', 'should', 'show', 'shower', 'shows', 'sick', 'side', 'sigh', 'sign', 'silly', 'sims', 'since', 'singing', 'sister', 'site', 'sitting', 'sleep', 'sleeping', 'sleepy', 'slept', 'slow', 'small', 'smile', 'so', 'some', 'someone', 'something', 'sometimes', 'son', 'song', 'songs', 'soo', 'soon', 'sooo', 'soooo', 'sore', 'sorry', 'sound', 'sounds', 'special', 'spend', 'spending', 'spent', 'star', 'start', 'started', 'starting', 'starts', 'stay', 'still', 'stomach', 'stop', 'store', 'story', 'straight', 'stuck', 'study', 'studying', 'stuff', 'stupid', 'such', 'suck', 'sucks', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'super', 'support', 'supposed', 'sure', 'sweet', 'take', 'takes', 'taking', 'talk', 'talking', 'taylor', 'tea', 'team', 'tell', 'test', 'text', 'than', 'thank', 'thanks', 'that', 'thats', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'thinks', 'this', 'tho', 'those', 'though', 'thought', 'three', 'throat', 'through', 'thru', 'thursday', 'thx', 'tickets', 'til', 'till', 'time', 'times', 'tinyurl', 'tired', 'to', 'today', 'together', 'told', 'tom', 'tommcfly', 'tomorrow', 'tonight', 'too', 'took', 'top', 'totally', 'tour', 'town', 'traffic', 'train', 'tried', 'trip', 'true', 'try', 'trying', 'tuesday', 'turn', 'tv', 'tweet', 'tweeting', 'tweets', 'twilight', 'twitpic', 'twitter', 'two', 'ugh', 'uk', 'under', 'understand', 'unfortunately', 'until', 'up', 'update', 'updates', 'upset', 'ur', 'us', 'use', 'used', 'using', 'vacation', 've', 'vegas', 'version', 'very', 'via', 'video', 'visit', 'voice', 'wait', 'waiting', 'wake', 'walk', 'wanna', 'want', 'wanted', 'wants', 'warm', 'was', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'we', 'wear', 'weather', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weeks', 'weird', 'welcome', 'well', 'went', 'were', 'what', 'whats', 'when', 'where', 'which', 'while', 'white', 'who', 'whole', 'why', 'wife', 'will', 'win', 'wine', 'wish', 'wishes', 'wishing', 'wit', 'with', 'without', 'woke', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woo', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'write', 'writing', 'wrong', 'wtf', 'www', 'xd', 'xoxo', 'xx', 'xxx', 'ya', 'yay', 'yea', 'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yet', 'yo', 'you', 'young', 'your', 'yourself', 'youtube', 'yum', 'yup']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjQXIhYtNl1a"
   },
   "source": [
    "Normalmente, quando usamos o vetorizador, escrevemos código como este:\n",
    "    \n",
    "`` `python\n",
    "vetores = vectorizer.fit_transform (....)\n",
    "`` `\n",
    "\n",
    "Que aprende todas as palavras ** e ** as conta. Neste caso ** já temos a lista de palavras que conhecemos, queremos apenas contá-las. ** Portanto, em vez de `.fit_transform`, usamos apenas` .transform`:\n",
    "\n",
    "`` `python\n",
    "vetores_desconhecidos = vectorizer.transform (desconhecido.content)\n",
    "desconhecido_words_df = ......\n",
    "`` `\n",
    "\n",
    "Termine de fazer seu `unknown_words_df` na célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1633378982213,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Eq2AO8vINl1a",
    "outputId": "4e68d960-8cf9-42bc-e60f-91676c5cbd8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>2day</th>\n",
       "      <th>2nd</th>\n",
       "      <th>30</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>after</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>again</th>\n",
       "      <th>ago</th>\n",
       "      <th>agree</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ahhh</th>\n",
       "      <th>air</th>\n",
       "      <th>album</th>\n",
       "      <th>all</th>\n",
       "      <th>almost</th>\n",
       "      <th>alone</th>\n",
       "      <th>already</th>\n",
       "      <th>alright</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>annoying</th>\n",
       "      <th>another</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>worked</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>worry</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wtf</th>\n",
       "      <th>www</th>\n",
       "      <th>xd</th>\n",
       "      <th>xoxo</th>\n",
       "      <th>xx</th>\n",
       "      <th>xxx</th>\n",
       "      <th>ya</th>\n",
       "      <th>yay</th>\n",
       "      <th>yea</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100   11   12   15  1st  ...  young  your  yourself  youtube  yum  yup\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passe pelo vetorizador\n",
    "\n",
    "# transform, not fit_transform, porque já aprendemos todas as nossas palavras\n",
    "unknown_vectors = vectorizer.transform(unknown.content)\n",
    "unknown_words_df = pd.DataFrame(unknown_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "unknown_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdtSSQqLNl1a"
   },
   "source": [
    "Confirme se `unknown_words_df` tem 11 linhas e 2.000 colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1633378982214,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "9UN6-XWrNl1a",
    "outputId": "f68725d5-519e-42b3-b61b-7ec916827f03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr2O90RmNl1b"
   },
   "source": [
    "### Predizendo com nossos modelos\n",
    "\n",
    "Para fazer uma previsão para cada uma de nossas sentenças, você pode usar `.predict` com cada um de nossos modelos. Por exemplo, seria assim para regressão linear:\n",
    "\n",
    "```python\n",
    "desconhecido ['pred_logreg'] = logreg.predict (desconhecido_words_df)\n",
    "```\n",
    "\n",
    "Para adicionar a previsão de regressão logística, você executaria um código `.predict` semelhante, que forneceria um` 0` (negativo) ou um `1` (positivo). A diferença entre os dois é que, para regressão logística, você também pode ** perguntar sobre a probabilidade de que a frase esteja na categoria `1` ** em vez de simplesmente na categoria. Para fazer isso, você usa este código:\n",
    "\n",
    "```python\n",
    "desconhecido ['pred_logreg_prob'] = linreg.predict_proba (unknown_words_df) [:, 1]\n",
    "```\n",
    "\n",
    "** Adicione novas colunas para cada um dos modelos que você treinou. ** Se o modelo tiver um `.predict_proba`, adicione-o também como uma coluna.\n",
    "\n",
    "* ** Dica: ** Tab é útil para saber se `.predict_proba` é uma opção.\n",
    "* ** Dica: ** não se esqueça de `[:, 1]` após `.predict_proba`, significa\" me dê a probabilidade para a categoria `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1633378982214,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "RrZgmFjrNl1b"
   },
   "outputs": [],
   "source": [
    "# Predict using all our models. \n",
    "\n",
    "# Logistic Regression predictions + probabilities\n",
    "unknown['pred_logreg'] = logreg.predict(unknown_words_df)\n",
    "unknown['pred_logreg_proba'] = logreg.predict_proba(unknown_words_df)[:,1]\n",
    "\n",
    "# Random forest predictions + probabilities\n",
    "unknown['pred_forest'] = forest.predict(unknown_words_df)\n",
    "unknown['pred_forest_proba'] = forest.predict_proba(unknown_words_df)[:,1]\n",
    "\n",
    "# SVC predictions\n",
    "unknown['pred_svc'] = svc.predict(unknown_words_df)\n",
    "\n",
    "# Bayes predictions + probabilities\n",
    "unknown['pred_bayes'] = bayes.predict(unknown_words_df)\n",
    "unknown['pred_bayes_proba'] = bayes.predict_proba(unknown_words_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1633378982214,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "Wn2k2iCoNl1b",
    "outputId": "fd3b7d7b-0864-4ac9-d107-92d64279f241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pred_logreg</th>\n",
       "      <th>pred_logreg_proba</th>\n",
       "      <th>pred_forest</th>\n",
       "      <th>pred_forest_proba</th>\n",
       "      <th>pred_svc</th>\n",
       "      <th>pred_bayes</th>\n",
       "      <th>pred_bayes_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love love love love this kitten</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate hate hate hate this keyboard</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009595</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm not sure how I feel about toast</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180953</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you see the baseball game yesterday?</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The package was delivered late and the contents were broken</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trashy television shows are some of my favorites</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm seeing a Kubrick film tomorrow, I hear not so great things about it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I find chirping birds irritating, but I know I'm not the only one</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    content  ...  pred_bayes_proba\n",
       "0                                         I love love love love this kitten  ...          0.747222\n",
       "1                                       I hate hate hate hate this keyboard  ...          0.122383\n",
       "2                                       I'm not sure how I feel about toast  ...          0.416819\n",
       "3                                  Did you see the baseball game yesterday?  ...          0.509662\n",
       "4               The package was delivered late and the contents were broken  ...          0.219788\n",
       "5                          Trashy television shows are some of my favorites  ...          0.534234\n",
       "6  I'm seeing a Kubrick film tomorrow, I hear not so great things about it.  ...          0.533493\n",
       "7         I find chirping birds irritating, but I know I'm not the only one  ...          0.295739\n",
       "\n",
       "[8 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uiRJeKfNl1c"
   },
   "source": [
    "### Perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfU8vFqONl1c"
   },
   "source": [
    "* O que os números significam? Qual é a diferença entre 0 e 1? A 0,5? Números negativos?\n",
    "* Houve alguma frase sobre a qual os classificadores pareciam discordar? Como você se sente sobre a quantidade de discordância deles?\n",
    "* Qual é a diferença entre usar um 0/1 para falar sobre sentimento em comparação com 0-1? Quando você pode usar um em comparação com o outro?\n",
    "* Qual é a diferença entre o modelo de regressão linear e os outros modelos que estamos usando? Por que pode ou não caber?\n",
    "* Entre 0-1, qual intervalo você acha que conta como \"negativo\", \"positivo\" e \"neutro\"?\n",
    "* A variação nas pontuações reflete a variação que você veria entre as pessoas? Ou é melhor ou pior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ7M3qJfNl1c"
   },
   "source": [
    "## Testando nossos modelos\n",
    "\n",
    "Podemos ver ** qual modelo tem o melhor desempenho! ** Lembra como treinamos nossos modelos em tweets? Podemos perguntar a cada modelo sobre cada tweet e ver se obtém a resposta certa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1633378982215,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "D2G1MoXONl1d",
    "outputId": "86caa0e4-86bd-4c0a-a930-25b4c1497649"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today  coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!!  I don't really have a life.....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                                                                                                               text\n",
       "0         0                                                                                                      @kconsidder You never tweet  \n",
       "1         0                                                                                                 Sick today  coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that \n",
       "3         1                                                                                Wii fit says I've lost 10 pounds since last time   \n",
       "4         0                                                                         @MrKinetik Not a thing!!!  I don't really have a life....."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZMjwD2lNl1d"
   },
   "source": [
    "Nosso dataframe original é uma lista de muitos, muitos tweets. Transformamos isso em `X` - palavras vetorizadas - e` y` - seja o tweet negativo ou positivo.\n",
    "\n",
    "Antes de usarmos `.fit (X, y)` para treinar em todos os nossos dados. Em vez disso, ** podemos testar nossos modelos ** fazendo uma divisão teste / trem e ver se as previsões correspondem aos rótulos reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1633378982215,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "mtsClvogNl1d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22374,
     "status": "ok",
     "timestamp": 1633379004563,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "F6Ald4UANl1d",
    "outputId": "ccd79d5e-9aff-424b-f008-da76774d2618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic regression\n",
      "Training random forest\n",
      "Training SVC\n",
      "Training Naive Bayes\n",
      "CPU times: user 27.9 s, sys: 901 ms, total: 28.8 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Training logistic regression\")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training random forest\")\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training SVC\")\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Naive Bayes\")\n",
    "bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "971sGBinNl1e"
   },
   "source": [
    "### Matrizes de confusão\n",
    "\n",
    "Para ver se eles se saíram bem, usaremos uma [\"matriz de confusão\"] (https://en.wikipedia.org/wiki/Confusion_matrix) para cada um. Acho que as matrizes de confusão são chamadas assim porque são confusas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633379004564,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "3jf5m2mdNl1e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LXG4aPbNl1e"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1633379004952,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "FW5VlxRPNl1e",
    "outputId": "ccd1734b-5c0e-4d68-a8a3-b3a3cf97a2a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>2743</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>915</td>\n",
       "      <td>2860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                2743                 982\n",
       "Is positive                 915                2860"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6hIW4qqNl1f"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1633379005318,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "9RSoiRv6Nl1f",
    "outputId": "a7d87821-1da3-4660-e358-2dddaa0aff67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>2774</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1126</td>\n",
       "      <td>2649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                2774                 951\n",
       "Is positive                1126                2649"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdcYtZxNNl1f"
   },
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1633379005318,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "db1pOAzBNl1g",
    "outputId": "767250bc-20ba-47d0-8ae8-e5873e25b7dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>2741</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>896</td>\n",
       "      <td>2879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                2741                 984\n",
       "Is positive                 896                2879"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xczqIZyQNl1g"
   },
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1633379005319,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "yuCwJu99Nl1g",
    "outputId": "4d4bbeb6-f22e-499b-e5b0-bd382199d2a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>2803</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>1039</td>\n",
       "      <td>2736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative                2803                 922\n",
       "Is positive                1039                2736"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k635vxI2Nl1h"
   },
   "source": [
    "### Matrizes de confusão baseadas em porcentagem\n",
    "\n",
    "Esses são irritantes porque são apenas números. Vamos tentar porcentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4LinKM4Nl1h"
   },
   "source": [
    "#### Logisitic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633379005319,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "gnFSwbBANl1h",
    "outputId": "02cf6df9-74a6-454b-df39-0c32bee8be87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.736376</td>\n",
       "      <td>0.263624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.242384</td>\n",
       "      <td>0.757616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.736376            0.263624\n",
       "Is positive            0.242384            0.757616"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCA-LQgnNl1i"
   },
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1633379005320,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "zS5W96_MNl1i",
    "outputId": "6950ee3c-537a-4786-a33b-e1547c858cae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.736376</td>\n",
       "      <td>0.263624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.242384</td>\n",
       "      <td>0.757616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.736376            0.263624\n",
       "Is positive            0.242384            0.757616"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNBx0RNgNl1i"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1633379006036,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "c_87hYGYNl1i",
    "outputId": "7884972e-29b1-4845-fb25-ebdf9400f67b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.744698</td>\n",
       "      <td>0.255302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.298278</td>\n",
       "      <td>0.701722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.744698            0.255302\n",
       "Is positive            0.298278            0.701722"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlUs0UBhNl1j"
   },
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1633379006037,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "T4ZJ2mjbNl1j",
    "outputId": "d8f645d0-a8fb-423c-d3c7-73ae3b5280fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.735839</td>\n",
       "      <td>0.264161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.237351</td>\n",
       "      <td>0.762649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.735839            0.264161\n",
       "Is positive            0.237351            0.762649"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = svc.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_DzJmv6Nl1j"
   },
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1633379006038,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "zpH83QKhNl1j",
    "outputId": "ed42a1f3-e943-4b5e-8f2b-e57d178e6af7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted negative</th>\n",
       "      <th>Predicted positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is negative</th>\n",
       "      <td>0.752483</td>\n",
       "      <td>0.247517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is positive</th>\n",
       "      <td>0.275232</td>\n",
       "      <td>0.724768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Predicted negative  Predicted positive\n",
       "Is negative            0.752483            0.247517\n",
       "Is positive            0.275232            0.724768"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = bayes.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['negative', 'positive'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKnedZk0Nl1k"
   },
   "source": [
    "## Análise\n",
    "\n",
    "Se você não estiver satisfeito com uma ferramenta, tente criar a sua própria! Isso é exatamente o que tentamos fazer, usando o ** conjunto de dados Sentiment140 ** e vários algoritmos de aprendizado de máquina.\n",
    "\n",
    "Sentiment140 é um banco de dados de tweets que vêm pré-rotulados com sentimentos positivos ou negativos, atribuídos automaticamente pela presença de um `:)` ou `: (`. Nosso primeiro passo foi usar um ** vetorizador ** para converter os tweets em números um computador poderia entender.\n",
    "\n",
    "Depois disso, construímos quatro ** modelos ** diferentes usando diferentes algoritmos de aprendizado de máquina. Cada um recebeu uma lista das ** características ** de cada tweet - as palavras - e o ** rótulo ** de cada tweet - o sentimento - na esperança de que mais tarde pudesse prever os rótulos se recebesse novos tweets. Este processo de ensino do algoritmo é chamado de ** treinamento **.\n",
    "\n",
    "Para testar nossos algoritmos, dividimos nossos dados em seções - dados de ** treinar ** e ** testar **. Você ensina o algoritmo com o primeiro grupo e, em seguida, pede previsões para o segundo conjunto. Você pode então comparar suas previsões com as respostas certas usando uma ** matriz de confusão **.\n",
    "\n",
    "Embora ** diferentes algoritmos levem diferentes quantidades de tempo para treinar **, todos eles acabaram com cerca de 70-75% de precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633379006038,
     "user": {
      "displayName": "Leonardo Mendonza",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj5F1JVSmHodKCvWHgDPYmDyFo_nUl5lqEXNbsW=s64",
      "userId": "09205135724810578413"
     },
     "user_tz": 180
    },
    "id": "7PAVO8tANl1k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Projeto_analise_de_sentimento.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
